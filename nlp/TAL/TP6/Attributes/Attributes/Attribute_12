backpropagation
gradient descent
stochastic gradient descent
sgd
adam optimizer
rmsprop
momentum
learning rate scheduling
loss function
regularization
l1
l2
dropout
batch normalization
weight initialization
early stopping
overfitting
underfitting