('<s>', 'Cross')	1	0.100000
('Cross', 'domain')	1	1.000000
('domain', 'association')	2	0.500000
('association', 'using')	1	0.500000
('using', 'transfer')	1	0.500000
('transfer', 'subspace')	1	0.333333
('subspace', 'learning')	2	0.666667
('learning', '</s>')	1	0.166667
('</s>', '<s>')	9	0.900000
('<s>', 'Transfer')	1	0.100000
('Transfer', 'learning')	1	1.000000
('learning', 'has')	1	0.166667
('has', 'gained')	1	1.000000
('gained', 'more')	1	1.000000
('more', 'attention')	1	1.000000
('attention', 'recently')	1	1.000000
('recently', 'by')	1	1.000000
('by', 'utilizing')	1	1.000000
('utilizing', 'knowledge')	1	1.000000
('knowledge', 'acquired')	1	1.000000
('acquired', 'from')	1	1.000000
('from', 'one')	1	0.333333
('one', 'domain')	1	1.000000
('domain', 'to')	1	0.250000
('to', 'advance')	1	0.200000
('advance', 'a')	1	1.000000
('a', 'learning')	1	0.142857
('learning', 'performance')	1	0.166667
('performance', 'in')	1	1.000000
('in', 'another')	1	0.250000
('another', 'domain')	1	1.000000
('domain', '</s>')	1	0.250000
('<s>', 'Existing')	1	0.100000
('Existing', 'homogeneous')	1	1.000000
('homogeneous', 'transfer')	1	1.000000
('transfer', 'learning')	2	0.666667
('learning', 'methods')	1	0.166667
('methods', 'have')	1	1.000000
('have', 'progressed')	1	1.000000
('progressed', 'to')	1	1.000000
('to', 'a')	2	0.400000
('a', 'point')	1	0.142857
('point', 'where')	1	1.000000
('where', 'feature')	1	0.250000
('feature', 'spaces')	1	1.000000
('spaces', 'are')	1	1.000000
('are', 'common')	1	0.333333
('common', 'in')	1	1.000000
('in', 'training')	1	0.250000
('training', 'and')	3	0.600000
('and', 'testing')	3	0.375000
('testing', 'domains')	3	0.600000
('domains', '</s>')	1	0.250000
('<s>', 'However')	1	0.100000
('However', 'heterogeneous')	1	1.000000
('heterogeneous', 'transfer')	1	1.000000
('learning', 'is')	1	0.166667
('is', 'still')	1	0.166667
('still', 'in')	1	1.000000
('in', 'its')	1	0.250000
('its', 'nascent')	1	1.000000
('nascent', 'stage')	1	1.000000
('stage', 'where')	1	1.000000
('where', 'features')	1	0.250000
('features', 'of')	1	1.000000
('of', 'training')	1	0.500000
('domains', 'are')	1	0.250000
('are', 'different')	1	0.333333
('different', '</s>')	1	1.000000
('<s>', 'Taking')	1	0.100000
('Taking', 'this')	1	1.000000
('this', 'into')	1	1.000000
('into', 'account')	1	1.000000
('account', 'Bregman')	1	1.000000
('Bregman', 'Divergence')	1	1.000000
('Divergence', 'Regularization')	1	1.000000
('Regularization', 'is')	1	1.000000
('is', 'used')	1	0.166667
('used', 'to')	1	0.333333
('to', 'minimize')	1	0.200000
('minimize', 'the')	1	1.000000
('the', 'probability')	1	0.500000
('probability', 'distribution')	1	1.000000
('distribution', 'difference')	1	1.000000
('difference', 'between')	1	1.000000
('between', 'training')	1	0.500000
('domains', 'and')	1	0.250000
('and', 'to')	1	0.125000
('to', 'take')	1	0.200000
('take', 'them')	1	1.000000
('them', 'together')	1	1.000000
('together', 'to')	1	1.000000
('a', 'shared')	1	0.142857
('shared', 'subspace')	1	1.000000
('subspace', '</s>')	1	0.333333
('<s>', 'To')	1	0.100000
('To', 'discriminate')	1	1.000000
('discriminate', 'data')	1	1.000000
('data', 'within')	1	0.333333
('within', 'individual')	1	1.000000
('individual', 'domains')	1	1.000000
('domains', 'a')	1	0.250000
('a', 'projection')	1	0.142857
('projection', 'matrix')	1	1.000000
('matrix', 'is')	1	1.000000
('is', 'obtained')	1	0.166667
('obtained', 'using')	1	1.000000
('using', 'Fisher')	1	0.500000
('Fisher', 'Linear')	1	1.000000
('Linear', 'Discriminant')	1	1.000000
('Discriminant', 'Analysis')	1	1.000000
('Analysis', 'subspace')	1	1.000000
('learning', 'algorithm')	1	0.166667
('algorithm', '</s>')	1	1.000000
('<s>', 'Experimentation')	1	0.100000
('Experimentation', 'is')	1	1.000000
('is', 'performed')	3	0.500000
('performed', 'on')	3	1.000000
('on', 'two')	1	0.333333
('two', 'efficiently')	1	1.000000
('efficiently', 'used')	1	1.000000
('used', 'biometrics')	1	0.333333
('biometrics', 'the')	1	1.000000
('the', 'face')	1	0.500000
('face', 'and')	2	0.400000
('and', 'fingerprint')	3	0.375000
('fingerprint', '</s>')	1	0.200000
('<s>', 'Two')	1	0.100000
('Two', 'types')	1	1.000000
('types', 'of')	1	1.000000
('of', 'cross-domain')	1	0.500000
('cross-domain', 'settings')	1	1.000000
('settings', 'are')	1	1.000000
('are', 'used')	1	0.333333
('used', '1')	1	0.333333
('1', 'Face')	1	1.000000
('Face', 'Finger2Finger')	1	1.000000
('Finger2Finger', 'where')	1	1.000000
('where', 'training')	2	0.500000
('training', 'samples')	2	0.400000
('samples', 'come')	2	0.333333
('come', 'from')	2	1.000000
('from', 'face')	1	0.333333
('face', 'labeled')	1	0.200000
('labeled', 'samples')	2	1.000000
('samples', 'and')	2	0.333333
('fingerprint', 'unlabeled')	1	0.200000
('unlabeled', 'samples')	2	1.000000
('samples', 'data')	2	0.333333
('data', 'sets')	2	0.666667
('sets', 'while')	2	1.000000
('while', 'testing')	2	1.000000
('testing', 'is')	2	0.400000
('on', 'a')	2	0.666667
('a', 'fingerprint')	1	0.142857
('fingerprint', 'dataset')	1	0.200000
('dataset', '</s>')	2	1.000000
('<s>', '2')	1	0.100000
('2', 'Finger')	1	1.000000
('Finger', 'Face2Face')	1	1.000000
('Face2Face', 'where')	1	1.000000
('from', 'fingerprint')	1	0.333333
('fingerprint', 'labeled')	1	0.200000
('and', 'face')	1	0.125000
('face', 'unlabeled')	1	0.200000
('a', 'face')	1	0.142857
('face', 'dataset')	1	0.200000
('<s>', 'This')	1	0.100000
('This', 'paper')	1	1.000000
('paper', 'proposes')	1	1.000000
('proposes', 'a')	1	1.000000
('a', 'cross')	1	0.142857
('cross', 'domain')	1	1.000000
('association', 'between')	1	0.500000
('between', 'face')	1	0.500000
('fingerprint', 'that')	1	0.200000
('that', 'finds')	1	1.000000
('finds', 'utility')	1	1.000000
('utility', 'in')	1	1.000000
('in', 'forensic')	1	0.250000
('forensic', 'applications')	1	1.000000
('applications', '.')	1	1.000000
('.', '</s>')	1	1.000000
