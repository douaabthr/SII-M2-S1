('<s>', 'A')	2	0.153846
('A', 'novel')	1	0.500000
('novel', 'improved')	1	0.500000
('improved', 'prediction')	1	1.000000
('prediction', 'of')	2	0.500000
('of', 'protein')	2	0.285714
('protein', 'structural')	1	0.333333
('structural', 'class')	2	1.000000
('class', 'using')	1	0.500000
('using', 'deep')	1	1.000000
('deep', 'recurrent')	1	0.333333
('recurrent', 'neural')	1	0.500000
('neural', 'network')	1	1.000000
('network', '</s>')	1	0.500000
('</s>', '<s>')	12	0.923077
('<s>', 'For')	1	0.076923
('For', 'last')	1	1.000000
('last', 'few')	1	1.000000
('few', 'decades')	1	1.000000
('decades', 'sequence')	1	1.000000
('sequence', 'arrangement')	1	0.333333
('arrangement', 'of')	1	1.000000
('of', 'amino')	1	0.142857
('amino', 'acids')	1	0.500000
('acids', 'have')	1	1.000000
('have', 'been')	2	0.666667
('been', 'utilized')	1	0.500000
('utilized', 'for')	1	1.000000
('for', 'the')	3	0.300000
('the', 'prediction')	1	0.142857
('protein', 'secondary')	2	0.666667
('secondary', 'structure')	1	0.500000
('structure', '</s>')	1	1.000000
('<s>', 'Recent')	1	0.076923
('Recent', 'methods')	1	1.000000
('methods', 'have')	1	1.000000
('have', 'applied')	1	0.333333
('applied', 'high')	1	0.500000
('high', 'dimensional')	1	1.000000
('dimensional', 'natural')	1	0.200000
('natural', 'language')	1	1.000000
('language', 'based')	1	1.000000
('based', 'features')	1	0.333333
('features', 'in')	1	0.500000
('in', 'machine')	1	0.166667
('machine', 'learning')	2	1.000000
('learning', 'models')	1	0.500000
('models', '</s>')	1	0.500000
('<s>', 'Performance')	1	0.076923
('Performance', 'measures')	1	1.000000
('measures', 'of')	1	1.000000
('of', 'machine')	1	0.142857
('learning', 'based')	1	0.500000
('based', 'models')	1	0.333333
('models', 'are')	1	0.500000
('are', 'significantly')	1	0.500000
('significantly', 'affected')	1	1.000000
('affected', 'by')	1	1.000000
('by', 'data')	1	1.000000
('data', 'size')	1	0.250000
('size', 'and')	1	1.000000
('and', 'data')	1	0.100000
('data', 'dimensionality')	1	0.250000
('dimensionality', '</s>')	1	1.000000
('<s>', 'It')	1	0.076923
('It', 'is')	1	1.000000
('is', 'a')	1	0.250000
('a', 'huge')	1	0.166667
('huge', 'challenge')	1	1.000000
('challenge', 'to')	1	1.000000
('to', 'develop')	1	0.250000
('develop', 'a')	1	1.000000
('a', 'generic')	1	0.166667
('generic', 'model')	1	1.000000
('model', 'which')	1	1.000000
('which', 'can')	1	1.000000
('can', 'be')	1	1.000000
('be', 'trained')	1	1.000000
('trained', 'to')	1	1.000000
('to', 'perform')	1	0.250000
('perform', 'both')	1	1.000000
('both', 'for')	1	0.250000
('for', 'small')	1	0.100000
('small', 'and')	2	0.500000
('and', 'large')	3	0.300000
('large', 'sized')	3	1.000000
('sized', 'datasets')	2	0.500000
('datasets', 'in')	1	0.333333
('in', 'a')	2	0.333333
('a', 'low')	2	0.333333
('low', 'dimensional')	4	0.800000
('dimensional', 'framework')	1	0.200000
('framework', '</s>')	1	1.000000
('<s>', 'In')	1	0.076923
('In', 'the')	1	1.000000
('the', 'present')	1	0.142857
('present', 'research')	1	1.000000
('research', 'we')	1	0.500000
('we', 'suggest')	1	0.333333
('suggest', 'a')	1	1.000000
('dimensional', 'representation')	1	0.200000
('representation', 'for')	1	0.250000
('for', 'both')	2	0.200000
('both', 'small')	2	0.500000
('datasets', '</s>')	1	0.333333
('A', 'hybrid')	1	0.500000
('hybrid', 'space')	1	1.000000
('space', 'of')	1	0.500000
('of', 'Atchley')	1	0.142857
('Atchley', 's')	1	1.000000
('s', 'factors')	1	1.000000
('factors', 'II')	1	1.000000
('II', 'IV')	1	1.000000
('IV', 'V')	1	1.000000
('V', 'electron')	1	1.000000
('electron', 'ion')	1	1.000000
('ion', 'interaction')	1	1.000000
('interaction', 'potential')	1	1.000000
('potential', 'and')	1	1.000000
('and', 'SkipGram')	1	0.100000
('SkipGram', 'based')	1	1.000000
('based', 'word2vec')	1	0.333333
('word2vec', 'have')	1	1.000000
('been', 'employed')	1	0.500000
('employed', 'for')	1	1.000000
('for', 'amino')	1	0.100000
('amino', 'acid')	1	0.500000
('acid', 'sequence')	1	1.000000
('sequence', 'representation')	1	0.333333
('representation', '</s>')	1	0.250000
('<s>', 'Subsequently')	1	0.076923
('Subsequently', 'Stockwell')	1	1.000000
('Stockwell', 'transformation')	1	1.000000
('transformation', 'is')	1	1.000000
('is', 'applied')	1	0.250000
('applied', 'to')	1	0.500000
('to', 'the')	1	0.250000
('the', 'representation')	1	0.142857
('representation', 'to')	1	0.250000
('to', 'preserve')	1	0.250000
('preserve', 'features')	1	1.000000
('features', 'both')	1	0.500000
('both', 'in')	1	0.250000
('in', 'time')	1	0.166667
('time', 'and')	1	0.333333
('and', 'frequency')	1	0.100000
('frequency', 'domains')	1	1.000000
('domains', '</s>')	1	1.000000
('<s>', 'Finally')	1	0.076923
('Finally', 'deep')	1	1.000000
('deep', 'gated')	1	0.333333
('gated', 'recurrent')	1	1.000000
('recurrent', 'network')	1	0.500000
('network', 'with')	1	0.500000
('with', 'dropout')	1	0.500000
('dropout', 'categorical-cross')	1	1.000000
('categorical-cross', 'entropy')	1	1.000000
('entropy', 'error')	1	1.000000
('error', 'estimation')	1	1.000000
('estimation', 'and')	1	1.000000
('and', 'Adam')	1	0.100000
('Adam', 'optimization')	1	1.000000
('optimization', 'is')	1	1.000000
('is', 'used')	1	0.250000
('used', 'for')	1	1.000000
('for', 'classification')	1	0.100000
('classification', 'purpose')	1	0.500000
('purpose', '</s>')	1	1.000000
('<s>', 'The')	3	0.230769
('The', 'introduced')	1	0.333333
('introduced', 'method')	1	1.000000
('method', 'results')	1	0.500000
('results', 'in')	1	1.000000
('in', 'better')	1	0.166667
('better', 'prediction')	1	1.000000
('prediction', 'accuracies')	1	0.250000
('accuracies', 'for')	2	1.000000
('small', '204,277')	1	0.250000
('204,277', 'and')	1	1.000000
('and', '498')	1	0.100000
('498', 'and')	1	0.500000
('sized', 'PDB25')	1	0.250000
('PDB25', 'Protein')	1	0.500000
('Protein', '640')	1	1.000000
('640', 'and')	1	0.500000
('and', 'FC699')	1	0.100000
('FC699', 'bench')	1	0.500000
('bench', 'mark')	1	1.000000
('mark', 'data')	1	1.000000
('data', 'sets')	2	0.500000
('sets', 'of')	1	0.500000
('of', 'low')	1	0.142857
('low', 'sequence')	1	0.200000
('sequence', 'similarity')	1	0.333333
('similarity', '25')	1	1.000000
('25', '40%')	1	1.000000
('40%', '</s>')	1	1.000000
('The', 'obtained')	1	0.333333
('obtained', 'classification')	1	1.000000
('classification', 'accuracies')	1	0.500000
('for', 'PDB25')	1	0.100000
('PDB25', '640')	1	0.500000
('640', 'FC699')	1	0.500000
('FC699', '498')	1	0.500000
('498', '277')	1	0.500000
('277', '204')	1	1.000000
('204', 'datasets')	1	1.000000
('datasets', 'are')	1	0.333333
('are', '84.2%')	1	0.500000
('84.2%', '94.31%')	1	1.000000
('94.31%', '93.1%')	1	1.000000
('93.1%', '95.9%')	1	1.000000
('95.9%', '94.5%')	1	1.000000
('94.5%', 'and')	1	1.000000
('and', '85.36%')	1	0.100000
('85.36%', 'respectively')	1	1.000000
('respectively', '</s>')	1	1.000000
('The', 'major')	1	0.333333
('major', 'contributions')	1	1.000000
('contributions', 'in')	1	1.000000
('in', 'this')	1	0.166667
('this', 'research')	1	1.000000
('research', 'is')	1	0.500000
('is', 'that')	1	0.250000
('that', 'for')	1	1.000000
('the', 'first')	2	0.285714
('first', 'time')	2	1.000000
('time', 'we')	1	0.333333
('we', 'verify')	1	0.333333
('verify', 'the')	1	0.500000
('the', 'protein')	1	0.142857
('secondary', 'structural')	1	0.500000
('class', 'prediction')	1	0.500000
('prediction', 'in')	1	0.250000
('a', 'very')	1	0.166667
('very', 'low')	1	1.000000
('dimensional', '18')	1	0.200000
('18', 'D')	1	1.000000
('D', 'feature')	1	1.000000
('feature', 'space')	1	0.500000
('space', 'with')	1	0.500000
('with', 'a')	1	0.500000
('a', 'novel')	1	0.166667
('novel', 'feature')	1	0.500000
('feature', 'representation')	1	0.500000
('representation', 'method')	1	0.250000
('method', '</s>')	1	0.500000
('<s>', 'Secondly')	1	0.076923
('Secondly', 'we')	1	1.000000
('we', 'also')	1	0.333333
('also', 'verify')	1	1.000000
('verify', 'for')	1	0.500000
('time', 'the')	1	0.333333
('the', 'behaviour')	1	0.142857
('behaviour', 'of')	1	1.000000
('of', 'deep')	1	0.142857
('deep', 'networks')	1	0.333333
('networks', 'for')	1	1.000000
('for', 'low')	1	0.100000
('dimensional', 'small')	1	0.200000
('small', 'sized')	1	0.250000
('sized', 'data')	1	0.250000
('sets', '.')	1	0.500000
('.', '</s>')	1	1.000000
