('<s>', 'An')	1	0.083333
('An', 'enhanced')	1	1.000000
('enhanced', 'sparse')	1	1.000000
('sparse', 'subset')	2	0.666667
('subset', 'selection')	7	0.875000
('selection', 'model')	3	0.300000
('model', 'based')	1	0.142857
('based', 'on')	1	1.000000
('on', 'adaptive')	1	0.333333
('adaptive', 'projection')	2	1.000000
('projection', 'distance')	2	0.666667
('distance', '</s>')	1	0.500000
('</s>', '<s>')	11	0.916667
('<s>', 'Subset')	1	0.083333
('Subset', 'selection')	1	1.000000
('selection', 'focuses')	1	0.100000
('focuses', 'on')	1	1.000000
('on', 'identifying')	1	0.333333
('identifying', 'representative')	1	1.000000
('representative', 'samples')	1	0.333333
('samples', 'from')	1	1.000000
('from', 'a')	1	0.500000
('a', 'large')	1	0.333333
('large', 'dataset')	1	1.000000
('dataset', 'to')	1	1.000000
('to', 'produce')	1	0.250000
('produce', 'a')	1	1.000000
('a', 'data')	1	0.333333
('data', 'subset')	1	0.125000
('subset', 'that')	1	0.125000
('that', 'can')	1	0.250000
('can', 'represent')	1	0.500000
('represent', 'the')	1	1.000000
('the', 'main')	1	0.058824
('main', 'features')	1	1.000000
('features', 'of')	1	0.500000
('of', 'the')	4	0.444444
('the', 'original')	2	0.117647
('original', 'data')	2	1.000000
('data', 'and')	1	0.125000
('and', 'also')	1	0.166667
('also', 'reduce')	1	0.500000
('reduce', 'the')	2	1.000000
('the', 'data')	3	0.176471
('data', 'size')	2	0.250000
('size', 'in')	1	0.500000
('in', 'an')	1	0.250000
('an', 'effective')	1	0.250000
('effective', 'way')	1	1.000000
('way', '</s>')	1	1.000000
('<s>', 'Sparse')	3	0.250000
('Sparse', 'representation')	1	0.333333
('representation', 'theory')	2	1.000000
('theory', 'puts')	1	0.500000
('puts', 'emphasis')	1	1.000000
('emphasis', 'on')	1	1.000000
('on', 'enhancing')	1	0.333333
('enhancing', 'the')	1	1.000000
('data', 'sparsity')	1	0.125000
('sparsity', 'while')	1	1.000000
('while', 'subset')	1	1.000000
('selection', 'aims')	1	0.100000
('aims', 'to')	1	1.000000
('to', 'reduce')	1	0.250000
('size', '</s>')	1	0.500000
('Sparse', 'subset')	1	0.333333
('selection', 'is')	1	0.100000
('is', 'an')	1	0.333333
('an', 'important')	1	0.250000
('important', 'branch')	1	1.000000
('branch', 'of')	1	1.000000
('of', 'subset')	2	0.222222
('selection', 'that')	1	0.100000
('that', 'incorporates')	1	0.250000
('incorporates', 'sparse')	1	1.000000
('sparse', 'representation')	1	0.333333
('theory', 'into')	1	0.500000
('into', 'the')	1	1.000000
('the', 'exploration')	1	0.058824
('exploration', 'of')	1	1.000000
('selection', '</s>')	1	0.100000
('Sparse', 'modeling')	1	0.333333
('modeling', 'representative')	1	1.000000
('representative', 'selection')	2	0.666667
('model', 'has')	1	0.142857
('has', 'demonstrated')	1	1.000000
('demonstrated', 'outstanding')	1	1.000000
('outstanding', 'performance')	1	1.000000
('performance', 'in')	1	1.000000
('in', 'data')	1	0.250000
('data', 'classification')	1	0.125000
('classification', 'and')	2	1.000000
('and', 'video')	1	0.166667
('video', 'summarization')	1	1.000000
('summarization', '</s>')	1	1.000000
('<s>', 'Nonetheless')	1	0.083333
('Nonetheless', 'it')	1	1.000000
('it', 'suffers')	1	1.000000
('suffers', 'from')	1	1.000000
('from', 'the')	1	0.500000
('the', 'issue')	1	0.058824
('issue', 'of')	1	1.000000
('of', 'poor')	1	0.111111
('poor', 'typicality')	1	1.000000
('typicality', 'of')	1	1.000000
('the', 'selected')	2	0.117647
('selected', 'representatives')	2	1.000000
('representatives', '</s>')	1	0.500000
('<s>', 'Although')	1	0.083333
('Although', 'some')	1	1.000000
('some', 'recent')	1	0.500000
('recent', 'works')	1	1.000000
('works', 'have')	1	1.000000
('have', 'addressed')	1	1.000000
('addressed', 'this')	1	1.000000
('this', 'problem')	1	1.000000
('problem', 'to')	1	1.000000
('to', 'some')	1	0.250000
('some', 'extent')	1	0.500000
('extent', 'by')	1	1.000000
('by', 'introducing')	1	0.250000
('introducing', 'the')	1	1.000000
('the', 'concept')	1	0.058824
('concept', 'of')	1	1.000000
('of', 'clustering')	1	0.111111
('clustering', 'coding')	3	1.000000
('coding', 'terms')	2	0.666667
('terms', 'most')	1	0.500000
('most', 'of')	1	1.000000
('the', 'clustering')	1	0.058824
('terms', 'constructed')	1	0.500000
('constructed', 'by')	1	1.000000
('by', 'these')	1	0.250000
('these', 'existing')	1	0.500000
('existing', 'methods')	1	1.000000
('methods', 'are')	1	1.000000
('are', 'implicit')	1	0.500000
('implicit', 'and')	1	1.000000
('and', 'the')	1	0.166667
('the', 'model')	1	0.058824
('model', 'structure')	1	0.142857
('structure', 'is')	1	1.000000
('is', 'complicated')	1	0.333333
('complicated', 'inefficient')	1	1.000000
('inefficient', 'and')	1	1.000000
('and', 'difficult')	1	0.166667
('difficult', 'to')	1	1.000000
('to', 'be')	1	0.250000
('be', 'understood')	1	1.000000
('understood', '</s>')	1	1.000000
('<s>', 'To')	2	0.166667
('To', 'overcome')	1	0.500000
('overcome', 'these')	1	1.000000
('these', 'difficulties')	1	0.500000
('difficulties', 'we')	1	1.000000
('we', 'propose')	1	1.000000
('propose', 'an')	1	1.000000
('an', 'adaptive')	1	0.250000
('projection', 'distance-based')	1	0.333333
('distance-based', 'sparse')	1	1.000000
('model', '</s>')	1	0.142857
('<s>', 'This')	1	0.083333
('This', 'model')	1	1.000000
('model', 'constructs')	1	0.142857
('constructs', 'a')	1	1.000000
('a', 'clustering')	1	0.333333
('coding', 'item')	1	0.333333
('item', 'by')	1	1.000000
('by', 'adaptively')	1	0.250000
('adaptively', 'calculating')	1	1.000000
('calculating', 'the')	1	1.000000
('the', 'projection')	1	0.058824
('distance', 'between')	1	0.500000
('between', 'data')	1	1.000000
('data', '</s>')	1	0.125000
('<s>', 'It')	1	0.083333
('It', 'can')	1	1.000000
('can', 'not')	1	0.500000
('not', 'only')	1	1.000000
('only', 'eliminate')	1	1.000000
('eliminate', 'redundant')	1	1.000000
('redundant', 'and')	1	1.000000
('and', 'noisy')	1	0.166667
('noisy', 'features')	1	1.000000
('features', 'in')	1	0.500000
('in', 'the')	1	0.250000
('data', 'but')	1	0.125000
('but', 'also')	1	1.000000
('also', 'ensure')	1	0.500000
('ensure', 'that')	1	1.000000
('that', 'the')	2	0.500000
('representatives', 'are')	1	0.500000
('are', 'more')	1	0.500000
('more', 'typical')	1	1.000000
('typical', '</s>')	1	1.000000
('To', 'solve')	1	0.500000
('solve', 'the')	1	1.000000
('the', 'proposed')	2	0.117647
('proposed', 'model')	2	1.000000
('model', 'an')	1	0.142857
('an', 'efficient')	1	0.250000
('efficient', 'algorithm')	1	1.000000
('algorithm', 'is')	1	1.000000
('is', 'developed')	1	0.333333
('developed', 'by')	1	1.000000
('by', 'virtue')	1	0.250000
('virtue', 'of')	1	1.000000
('the', 'alternating')	1	0.058824
('alternating', 'direction')	1	1.000000
('direction', 'method')	1	1.000000
('method', 'of')	1	1.000000
('of', 'multipliers')	1	0.111111
('multipliers', '</s>')	1	1.000000
('<s>', 'Extensive')	1	0.083333
('Extensive', 'experiments')	1	1.000000
('experiments', 'with')	1	1.000000
('with', 'comparative')	1	1.000000
('comparative', 'analysis')	1	1.000000
('analysis', 'demonstrate')	1	0.500000
('demonstrate', 'that')	1	1.000000
('model', 'outperforms')	1	0.142857
('outperforms', 'several')	1	1.000000
('several', 'state-of-the-art')	1	1.000000
('state-of-the-art', 'models')	1	1.000000
('models', 'in')	1	1.000000
('in', 'various')	1	0.250000
('various', 'tasks')	1	1.000000
('tasks', 'including')	1	1.000000
('including', 'subset')	1	1.000000
('selection', 'cluster')	1	0.100000
('cluster', 'analysis')	1	1.000000
('analysis', 'classification')	1	0.500000
('and', 'face')	1	0.166667
('face', 'image')	1	1.000000
('image', 'representative')	1	1.000000
('selection', '.')	1	0.100000
('.', '</s>')	1	1.000000
