('<s>', 'Emerging')	1	0.090909
('Emerging', 'deep')	1	1.000000
('deep', 'learning')	4	1.000000
('learning', 'approaches')	1	0.250000
('approaches', 'for')	1	1.000000
('for', 'urban')	2	0.250000
('urban', 'satellite')	3	0.428571
('satellite', 'image')	2	0.666667
('image', 'analysis')	2	1.000000
('analysis', 'a')	1	0.333333
('a', 'survey')	1	0.250000
('survey', 'on')	1	0.500000
('on', 'classification')	1	1.000000
('classification', 'segmentation')	2	0.500000
('segmentation', 'and')	2	0.500000
('and', 'change')	2	0.133333
('change', 'detection')	3	0.750000
('detection', '</s>')	2	0.500000
('</s>', '<s>')	10	0.909091
('<s>', 'The')	1	0.090909
('The', 'study')	1	1.000000
('study', 'of')	1	0.500000
('of', 'urban')	2	0.181818
('satellite', 'imagery')	1	0.333333
('imagery', 'has')	1	1.000000
('has', 'undergone')	1	1.000000
('undergone', 'a')	1	1.000000
('a', 'significant')	1	0.250000
('significant', 'transformation')	1	1.000000
('transformation', 'due')	1	1.000000
('due', 'to')	1	1.000000
('to', 'the')	1	0.500000
('the', 'emergence')	1	0.166667
('emergence', 'of')	1	1.000000
('of', 'deep')	2	0.181818
('learning', 'techniques')	1	0.250000
('techniques', '</s>')	1	1.000000
('<s>', 'This')	3	0.272727
('This', 'survey')	1	0.333333
('survey', 'thoroughly')	1	0.500000
('thoroughly', 'examines')	1	1.000000
('examines', 'current')	1	1.000000
('current', 'progress')	1	1.000000
('progress', 'in')	1	1.000000
('in', 'deep')	1	0.333333
('learning', 'models')	1	0.250000
('models', 'designed')	1	0.166667
('designed', 'for')	1	1.000000
('for', 'three')	1	0.125000
('three', 'primary')	1	1.000000
('primary', 'tasks')	1	1.000000
('tasks', 'classification')	1	1.000000
('detection', 'in')	1	0.250000
('in', 'urban')	2	0.666667
('urban', 'environments')	1	0.142857
('environments', '</s>')	1	1.000000
('<s>', 'A')	1	0.090909
('A', 'total')	1	1.000000
('total', 'of')	1	1.000000
('of', '114')	1	0.090909
('114', 'reviewed')	1	1.000000
('reviewed', 'studies')	1	1.000000
('studies', 'were')	1	1.000000
('were', 'analyzed')	1	0.500000
('analyzed', 'including')	1	1.000000
('including', 'convolutional')	1	0.500000
('convolutional', 'neural')	1	1.000000
('neural', 'networks')	1	1.000000
('networks', 'CNNs')	1	1.000000
('CNNs', 'hybrid')	1	1.000000
('hybrid', 'models')	1	1.000000
('models', 'and')	1	0.166667
('and', 'transformer-based')	1	0.066667
('transformer-based', 'models')	1	1.000000
('models', 'such')	2	0.333333
('such', 'as')	3	1.000000
('as', 'ResNet')	1	0.200000
('ResNet', 'UNet')	1	1.000000
('UNet', 'HRNet')	1	0.333333
('HRNet', 'BR-Net')	1	1.000000
('BR-Net', 'Mask2Former')	1	0.500000
('Mask2Former', 'TransCFCCNN')	1	0.500000
('TransCFCCNN', 'and')	1	1.000000
('and', 'STCD-EffV2T')	1	0.066667
('STCD-EffV2T', 'UNet')	2	1.000000
('UNet', '</s>')	1	0.333333
('<s>', 'Prominent')	1	0.090909
('Prominent', 'datasets')	1	1.000000
('datasets', 'such')	1	1.000000
('as', 'EuroSAT')	1	0.200000
('EuroSAT', 'UC-Merced')	1	1.000000
('UC-Merced', 'SpaceNet')	1	1.000000
('SpaceNet', 'DeepGlobe')	1	1.000000
('DeepGlobe', 'LEVIR-CD')	1	1.000000
('LEVIR-CD', 'and')	1	1.000000
('and', 'xBD')	1	0.066667
('xBD', 'were')	1	1.000000
('were', 'examined')	1	0.500000
('examined', 'alongside')	1	1.000000
('alongside', 'performance')	1	1.000000
('performance', 'metrics')	1	1.000000
('metrics', 'like')	1	1.000000
('like', 'accuracy')	1	0.500000
('accuracy', 'F1')	1	1.000000
('F1', 'score')	1	0.500000
('score', 'IoU')	1	1.000000
('IoU', 'precision')	1	0.500000
('precision', 'and')	1	1.000000
('and', 'recall')	1	0.066667
('recall', 'with')	1	1.000000
('with', 'results')	1	1.000000
('results', 'visualized')	1	1.000000
('visualized', 'through')	1	1.000000
('through', 'comparative')	1	1.000000
('comparative', 'bar')	1	1.000000
('bar', 'plots')	1	1.000000
('plots', '</s>')	1	1.000000
('<s>', 'Our')	1	0.090909
('Our', 'comparison')	1	1.000000
('comparison', 'analysis')	1	1.000000
('analysis', 'indicates')	1	0.333333
('indicates', 'that')	1	1.000000
('that', 'models')	1	1.000000
('as', 'GoogleNet')	1	0.200000
('GoogleNet', 'EfficientNet-B7')	1	1.000000
('EfficientNet-B7', 'and')	1	1.000000
('and', 'MaxViT')	1	0.066667
('MaxViT', 'achieve')	1	1.000000
('achieve', 'classification')	1	1.000000
('classification', 'accuracies')	1	0.250000
('accuracies', 'over')	1	1.000000
('over', '99%')	1	0.500000
('99%', 'while')	1	1.000000
('while', 'segmentation')	1	1.000000
('segmentation', 'models')	1	0.250000
('models', 'like')	1	0.166667
('like', 'Mask2Former')	1	0.500000
('Mask2Former', 'and')	1	0.500000
('and', 'BR-Net')	1	0.066667
('BR-Net', 'exhibit')	1	0.500000
('exhibit', 'IoU')	1	1.000000
('IoU', 'scores')	1	0.500000
('scores', 'over')	1	0.500000
('over', '92%')	1	0.500000
('92%', '</s>')	1	1.000000
('<s>', 'STCD-EffV2T')	1	0.090909
('UNet', 'achieves')	1	0.333333
('achieves', 'exceptional')	1	1.000000
('exceptional', 'F1')	1	1.000000
('F1', 'scores')	1	0.500000
('scores', 'of')	1	0.500000
('of', 'up')	1	0.090909
('up', 'to')	1	1.000000
('to', '98.79%')	1	0.500000
('98.79%', 'for')	1	1.000000
('for', 'change')	1	0.125000
('<s>', 'These')	1	0.090909
('These', 'models')	1	1.000000
('models', 'are')	1	0.166667
('are', 'crucial')	1	1.000000
('crucial', 'for')	1	1.000000
('urban', 'development')	1	0.142857
('development', 'and')	1	1.000000
('and', 'environmental')	2	0.133333
('environmental', 'change')	1	0.500000
('change', 'monitoring')	1	0.250000
('monitoring', 'facilitating')	1	1.000000
('facilitating', 'the')	1	1.000000
('the', 'classification')	1	0.166667
('classification', 'of')	1	0.250000
('of', 'land')	1	0.090909
('land', 'cover')	1	1.000000
('cover', 'types')	1	1.000000
('types', 'segmentation')	1	1.000000
('segmentation', 'of')	1	0.250000
('of', 'buildings')	1	0.090909
('buildings', 'roads')	1	1.000000
('roads', 'and')	1	1.000000
('and', 'urban')	1	0.066667
('urban', 'features')	1	0.142857
('features', 'as')	1	1.000000
('as', 'well')	1	0.200000
('well', 'as')	1	1.000000
('as', 'the')	1	0.200000
('the', 'detection')	1	0.166667
('detection', 'of')	1	0.250000
('urban', 'and')	1	0.142857
('environmental', 'changes')	1	0.500000
('changes', '</s>')	1	1.000000
('This', 'study')	1	0.333333
('study', 'defines')	1	0.500000
('defines', 'growing')	1	1.000000
('growing', 'trends')	1	1.000000
('trends', 'and')	1	1.000000
('and', 'challenges')	1	0.066667
('challenges', 'incorporating')	1	1.000000
('incorporating', 'model')	1	1.000000
('model', 'generalization')	1	1.000000
('generalization', 'dataset')	1	1.000000
('dataset', 'diversity')	1	0.500000
('diversity', 'and')	1	1.000000
('and', 'computing')	1	0.066667
('computing', 'complexity')	1	1.000000
('complexity', '</s>')	1	1.000000
('<s>', 'It')	1	0.090909
('It', 'additionally')	1	1.000000
('additionally', 'suggests')	1	1.000000
('suggests', 'future')	1	1.000000
('future', 'directions')	1	1.000000
('directions', 'including')	1	1.000000
('including', 'the')	1	0.500000
('the', 'use')	1	0.166667
('use', 'of')	1	1.000000
('of', 'Mamba')	1	0.090909
('Mamba', 'Networks')	1	1.000000
('Networks', 'for')	1	1.000000
('for', 'scalable')	1	0.125000
('scalable', 'temporal')	1	1.000000
('temporal', 'modeling')	1	1.000000
('modeling', 'the')	1	1.000000
('the', 'incorporation')	1	0.166667
('incorporation', 'of')	1	1.000000
('of', 'Vision')	1	0.090909
('Vision', 'Transformers')	1	1.000000
('Transformers', 'for')	1	1.000000
('for', 'enhanced')	1	0.125000
('enhanced', 'feature')	1	1.000000
('feature', 'extraction')	1	1.000000
('extraction', 'and')	1	1.000000
('and', 'the')	1	0.066667
('the', 'utilization')	1	0.166667
('utilization', 'of')	1	1.000000
('of', 'GANs')	1	0.090909
('GANs', 'for')	1	1.000000
('for', 'dataset')	1	0.125000
('dataset', 'augmentation')	1	0.500000
('augmentation', '</s>')	1	1.000000
('This', 'paper')	1	0.333333
('paper', 'offers')	1	1.000000
('offers', 'a')	1	1.000000
('a', 'comprehensive')	1	0.250000
('comprehensive', 'and')	1	1.000000
('and', 'systematic')	1	0.066667
('systematic', 'synthesis')	1	1.000000
('synthesis', 'of')	1	1.000000
('learning', 'methodologies')	1	0.250000
('methodologies', 'establishing')	1	1.000000
('establishing', 'a')	1	1.000000
('a', 'fundamental')	1	0.250000
('fundamental', 'reference')	1	1.000000
('reference', 'for')	1	1.000000
('for', 'subsequent')	1	0.125000
('subsequent', 'research')	1	1.000000
('research', 'in')	1	1.000000
('analysis', '.')	1	0.333333
('.', '</s>')	1	1.000000
