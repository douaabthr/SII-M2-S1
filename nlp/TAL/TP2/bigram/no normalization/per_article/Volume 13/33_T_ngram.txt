('<s>', 'Solving')	1	0.125000
('Solving', 'the')	1	1.000000
('the', 'twitter')	1	0.058824
('twitter', 'sentiment')	1	1.000000
('sentiment', 'analysis')	1	0.333333
('analysis', 'problem')	1	1.000000
('problem', 'based')	1	0.333333
('based', 'on')	4	1.000000
('on', 'a')	1	0.200000
('a', 'machine')	2	0.400000
('machine', 'learning-based')	1	0.333333
('learning-based', 'approach')	1	1.000000
('approach', '</s>')	1	0.500000
('</s>', '<s>')	7	0.875000
('<s>', 'Twitter')	1	0.125000
('Twitter', 'Sentiment')	1	0.500000
('Sentiment', 'Analysis')	1	1.000000
('Analysis', 'TSA')	1	1.000000
('TSA', 'as')	1	0.500000
('as', 'part')	1	0.333333
('part', 'of')	1	1.000000
('of', 'a')	1	0.125000
('a', 'text')	1	0.200000
('text', 'classification')	1	1.000000
('classification', 'task')	1	0.500000
('task', 'has')	1	1.000000
('has', 'been')	1	1.000000
('been', 'widely')	1	1.000000
('widely', 'attended')	1	1.000000
('attended', 'by')	1	1.000000
('by', 'researchers')	1	1.000000
('researchers', 'in')	1	1.000000
('in', 'recent')	1	0.250000
('recent', 'years')	1	1.000000
('years', '</s>')	1	1.000000
('<s>', 'This')	1	0.125000
('This', 'paper')	1	1.000000
('paper', 'presents')	1	1.000000
('presents', 'a')	1	1.000000
('machine', 'learning')	1	0.333333
('learning', 'approach')	1	1.000000
('approach', 'to')	1	0.500000
('to', 'solving')	1	1.000000
('solving', 'the')	1	1.000000
('the', 'TSA')	1	0.058824
('TSA', 'problem')	1	0.500000
('problem', 'in')	1	0.333333
('in', 'three')	1	0.250000
('three', 'phases')	1	1.000000
('phases', '</s>')	1	1.000000
('<s>', 'In')	2	0.250000
('In', 'the')	1	0.500000
('the', 'second')	1	0.058824
('second', 'phase')	1	1.000000
('phase', 'a')	1	1.000000
('a', 'suitable')	1	0.200000
('suitable', 'value')	1	1.000000
('value', 'for')	1	1.000000
('for', 'representing')	1	1.000000
('representing', 'each')	1	1.000000
('each', 'feature')	1	0.500000
('feature', 'in')	1	1.000000
('in', 'the')	1	0.250000
('the', 'Vector')	1	0.058824
('Vector', 'Space')	1	1.000000
('Space', 'Model')	1	1.000000
('Model', 'is')	1	1.000000
('is', 'determined')	1	0.333333
('determined', 'through')	1	1.000000
('through', 'the')	1	1.000000
('the', 'weighted')	2	0.117647
('weighted', 'combination')	1	0.500000
('combination', 'of')	1	1.000000
('of', 'the')	3	0.375000
('the', 'values')	1	0.058824
('values', 'obtained')	2	1.000000
('obtained', 'from')	2	0.666667
('from', 'four')	2	1.000000
('four', 'methods')	2	0.666667
('methods', 'i.e.')	1	0.333333
('i.e.', 'Term')	1	1.000000
('Term', 'Frequency')	1	1.000000
('Frequency', 'and')	1	0.500000
('and', 'Inverse')	1	0.200000
('Inverse', 'Document')	1	1.000000
('Document', 'Frequency')	1	1.000000
('Frequency', 'semantic')	1	0.500000
('semantic', 'similarity')	1	1.000000
('similarity', 'sentiment')	1	1.000000
('sentiment', 'scoring')	2	0.666667
('scoring', 'using')	1	0.500000
('using', 'SentiWordNet')	1	0.500000
('SentiWordNet', 'and')	1	1.000000
('and', 'sentiment')	1	0.200000
('scoring', 'based')	1	0.500000
('on', 'the')	3	0.600000
('the', 'class')	1	0.058824
('class', 'of')	1	1.000000
('of', 'tweets')	1	0.125000
('tweets', '</s>')	1	1.000000
('In', 'this')	1	0.500000
('this', 'manner')	1	1.000000
('manner', 'finding')	1	1.000000
('finding', 'the')	1	1.000000
('the', 'percentage')	1	0.058824
('percentage', 'of')	1	1.000000
('of', 'contributions')	1	0.125000
('contributions', 'or')	1	1.000000
('or', 'weights')	1	1.000000
('weights', 'of')	1	1.000000
('of', 'each')	1	0.125000
('each', 'method')	1	0.500000
('method', 'is')	2	0.500000
('is', 'defined')	1	0.333333
('defined', 'as')	1	1.000000
('as', 'an')	2	0.666667
('an', 'optimization')	1	0.500000
('optimization', 'problem')	1	1.000000
('problem', 'and')	1	0.333333
('and', 'solved')	1	0.200000
('solved', 'using')	1	1.000000
('using', 'a')	1	0.500000
('a', 'genetic')	1	0.200000
('genetic', 'algorithm')	1	1.000000
('algorithm', '</s>')	1	1.000000
('<s>', 'Also')	1	0.125000
('Also', 'the')	1	1.000000
('weighted', 'values')	1	0.500000
('methods', 'are')	1	0.333333
('are', 'combined')	1	1.000000
('combined', 'based')	1	1.000000
('the', 'Einstein')	1	0.058824
('Einstein', 'sum')	1	1.000000
('sum', 'as')	1	1.000000
('an', 'important')	1	0.500000
('important', 'T-conorm')	1	1.000000
('T-conorm', 'method')	1	1.000000
('method', '</s>')	1	0.250000
('<s>', 'Finally')	1	0.125000
('Finally', 'the')	1	1.000000
('the', 'performance')	1	0.058824
('performance', 'of')	1	1.000000
('the', 'proposed')	2	0.117647
('proposed', 'method')	2	1.000000
('is', 'tested')	1	0.333333
('tested', 'based')	1	1.000000
('the', 'accuracy')	1	0.058824
('accuracy', 'of')	1	1.000000
('of', 'support')	1	0.125000
('support', 'vector')	1	1.000000
('vector', 'machine')	1	1.000000
('machine', 'and')	1	0.333333
('and', 'multinomial')	1	0.200000
('multinomial', 'naïve')	1	1.000000
('naïve', 'Bayes')	1	1.000000
('Bayes', 'classification')	1	1.000000
('classification', 'algorithms')	1	0.500000
('algorithms', 'on')	1	1.000000
('on', 'four')	1	0.200000
('four', 'famous')	1	0.333333
('famous', 'Twitter')	1	1.000000
('Twitter', 'datasets')	1	0.500000
('datasets', 'namely')	1	1.000000
('namely', 'the')	1	1.000000
('the', 'Stanford')	1	0.058824
('Stanford', 'testing')	1	1.000000
('testing', 'dataset')	1	1.000000
('dataset', 'STS-Gold')	1	0.250000
('STS-Gold', 'dataset')	1	1.000000
('dataset', 'Obama-McCain')	1	0.250000
('Obama-McCain', 'Debate')	2	1.000000
('Debate', 'dataset')	2	1.000000
('dataset', 'and')	1	0.250000
('and', 'Strict')	1	0.200000
('Strict', 'Obama-McCain')	1	1.000000
('dataset', '</s>')	1	0.250000
('<s>', 'The')	1	0.125000
('The', 'obtained')	1	1.000000
('obtained', 'results')	1	0.333333
('results', 'show')	1	1.000000
('show', 'the')	1	1.000000
('the', 'high')	1	0.058824
('high', 'superiority')	1	1.000000
('superiority', 'of')	1	1.000000
('method', 'in')	1	0.250000
('in', 'comparison')	1	0.250000
('comparison', 'with')	1	1.000000
('with', 'the')	1	1.000000
('the', 'other')	1	0.058824
('other', 'methods')	1	1.000000
('methods', '.')	1	0.333333
('.', '</s>')	1	1.000000
