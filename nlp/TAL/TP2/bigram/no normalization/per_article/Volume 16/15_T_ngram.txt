('<s>', 'A')	1	0.111111
('A', 'method')	1	1.000000
('method', 'for')	1	0.166667
('for', 'fuzzy')	1	0.333333
('fuzzy', 'time')	3	0.500000
('time', 'series')	6	1.000000
('series', 'forecasting')	4	0.666667
('forecasting', 'based')	1	0.125000
('based', 'on')	2	1.000000
('on', 'interval')	1	0.333333
('interval', 'index')	2	1.000000
('index', 'number')	2	1.000000
('number', 'and')	2	0.666667
('and', 'membership')	2	0.200000
('membership', 'value')	2	1.000000
('value', 'using')	1	0.250000
('using', 'fuzzy')	1	1.000000
('fuzzy', 'c-means')	2	0.333333
('c-means', 'clustering')	2	1.000000
('clustering', '</s>')	1	0.500000
('</s>', '<s>')	8	0.888889
('<s>', 'Fuzzy')	1	0.111111
('Fuzzy', 'time')	1	1.000000
('forecasting', 'methods')	2	0.250000
('methods', 'are')	2	0.500000
('are', 'very')	1	0.142857
('very', 'popular')	1	1.000000
('popular', 'among')	1	1.000000
('among', 'researchers')	1	1.000000
('researchers', 'for')	1	0.500000
('for', 'predicting')	1	0.333333
('predicting', 'future')	1	1.000000
('future', 'values')	1	0.500000
('values', 'as')	1	1.000000
('as', 'they')	1	0.500000
('they', 'are')	1	1.000000
('are', 'not')	1	0.142857
('not', 'based')	1	1.000000
('on', 'the')	1	0.333333
('the', 'strict')	1	0.111111
('strict', 'assumptions')	1	1.000000
('assumptions', 'of')	1	1.000000
('of', 'traditional')	1	0.100000
('traditional', 'forecasting')	1	1.000000
('methods', '</s>')	1	0.250000
('<s>', 'Non-stochastic')	1	0.111111
('Non-stochastic', 'methods')	1	1.000000
('methods', 'of')	1	0.250000
('of', 'fuzzy')	2	0.200000
('forecasting', 'are')	1	0.125000
('are', 'preferred')	1	0.142857
('preferred', 'by')	1	1.000000
('by', 'the')	2	0.400000
('the', 'researchers')	1	0.111111
('researchers', 'over')	1	0.500000
('over', 'the')	1	1.000000
('the', 'years')	1	0.111111
('years', 'because')	1	1.000000
('because', 'these')	1	1.000000
('these', 'methods')	1	1.000000
('are', 'capable')	1	0.142857
('capable', 'to')	1	1.000000
('to', 'deal')	1	0.125000
('deal', 'with')	1	1.000000
('with', 'real')	1	0.500000
('real', 'life')	1	0.500000
('life', 'uncertainties')	1	1.000000
('uncertainties', 'and')	1	1.000000
('and', 'provide')	1	0.100000
('provide', 'significant')	1	1.000000
('significant', 'forecast')	1	1.000000
('forecast', '</s>')	1	1.000000
('<s>', 'There')	1	0.111111
('There', 'are')	1	1.000000
('are', 'generally')	1	0.142857
('generally', 'four')	1	1.000000
('four', 'factors')	1	1.000000
('factors', 'that')	1	0.500000
('that', 'determine')	1	1.000000
('determine', 'the')	1	1.000000
('the', 'performance')	2	0.222222
('performance', 'of')	1	0.250000
('of', 'the')	1	0.100000
('the', 'forecasting')	2	0.222222
('forecasting', 'method')	1	0.125000
('method', '1')	1	0.166667
('1', 'number')	1	0.500000
('number', 'of')	1	0.333333
('of', 'intervals')	2	0.200000
('intervals', 'NOIs')	1	0.333333
('NOIs', 'and')	2	1.000000
('and', 'length')	1	0.100000
('length', 'of')	1	0.500000
('intervals', 'to')	1	0.333333
('to', 'partition')	1	0.125000
('partition', 'universe')	1	1.000000
('universe', 'of')	1	1.000000
('of', 'discourse')	1	0.100000
('discourse', 'UOD')	1	1.000000
('UOD', '2')	1	0.500000
('2', 'fuzzification')	1	0.500000
('fuzzification', 'rules')	1	1.000000
('rules', 'or')	1	1.000000
('or', 'feature')	1	1.000000
('feature', 'representation')	1	1.000000
('representation', 'of')	1	1.000000
('of', 'crisp')	1	0.100000
('crisp', 'time')	1	0.500000
('series', '3')	1	0.166667
('3', 'method')	1	1.000000
('method', 'of')	2	0.333333
('of', 'establishing')	1	0.100000
('establishing', 'fuzzy')	1	1.000000
('fuzzy', 'logic')	1	0.166667
('logic', 'rule')	1	1.000000
('rule', 'FLRs')	1	0.500000
('FLRs', '4')	1	0.500000
('4', 'defuzzification')	1	1.000000
('defuzzification', 'rule')	1	1.000000
('rule', 'to')	1	0.500000
('to', 'get')	1	0.125000
('get', 'crisp')	1	1.000000
('crisp', 'forecasted')	1	0.500000
('forecasted', 'value')	1	1.000000
('value', '</s>')	2	0.500000
('<s>', 'Considering')	1	0.111111
('Considering', 'first')	1	1.000000
('first', 'two')	1	1.000000
('two', 'factors')	1	0.500000
('factors', 'to')	1	0.500000
('to', 'improve')	1	0.125000
('improve', 'the')	1	1.000000
('forecasting', 'accuracy')	2	0.250000
('accuracy', 'we')	1	0.500000
('we', 'proposed')	1	0.500000
('proposed', 'a')	1	0.333333
('a', 'modified')	1	0.333333
('modified', 'non-stochastic')	1	1.000000
('non-stochastic', 'method')	1	1.000000
('forecasting', 'in')	1	0.125000
('in', 'which')	1	1.000000
('which', 'interval')	1	1.000000
('value', 'are')	1	0.250000
('are', 'used')	2	0.285714
('used', 'as')	1	0.250000
('as', 'input')	1	0.500000
('input', 'features')	1	1.000000
('features', 'to')	1	1.000000
('to', 'predict')	1	0.125000
('predict', 'future')	1	1.000000
('future', 'value')	1	0.500000
('<s>', 'We')	2	0.222222
('We', 'suggested')	1	0.500000
('suggested', 'a')	1	1.000000
('a', 'rounding-off')	1	0.333333
('rounding-off', 'range')	1	1.000000
('range', 'and')	1	1.000000
('and', 'large')	1	0.100000
('large', 'step-size')	1	1.000000
('step-size', 'method')	1	1.000000
('method', 'to')	1	0.166667
('to', 'find')	1	0.125000
('find', 'the')	1	1.000000
('the', 'optimal')	1	0.111111
('optimal', 'NOIs')	1	1.000000
('and', 'used')	1	0.100000
('used', 'fuzzy')	1	0.250000
('clustering', 'process')	1	0.500000
('process', 'to')	1	1.000000
('to', 'divide')	1	0.125000
('divide', 'UOD')	1	1.000000
('UOD', 'into')	1	0.500000
('into', 'intervals')	1	1.000000
('intervals', 'of')	1	0.333333
('of', 'unequal')	1	0.100000
('unequal', 'length')	1	1.000000
('length', '</s>')	1	0.500000
('We', 'implement')	1	0.500000
('implement', 'two')	1	1.000000
('two', 'techniques')	1	0.500000
('techniques', '1')	1	0.500000
('1', 'regression')	1	0.500000
('regression', 'by')	1	1.000000
('by', 'support')	1	0.200000
('support', 'vector')	1	1.000000
('vector', 'machine')	1	1.000000
('machine', 'and')	1	1.000000
('and', '2')	1	0.100000
('2', 'neural')	1	0.500000
('neural', 'network')	1	1.000000
('network', 'by')	1	1.000000
('by', 'multilayer')	1	0.200000
('multilayer', 'perceptron')	1	1.000000
('perceptron', 'to')	1	1.000000
('to', 'establish')	1	0.125000
('establish', 'FLRs')	1	1.000000
('FLRs', '</s>')	1	0.500000
('<s>', 'To')	1	0.111111
('To', 'test')	1	1.000000
('test', 'our')	1	1.000000
('our', 'proposed')	1	1.000000
('proposed', 'method')	1	0.333333
('method', 'by')	1	0.166667
('by', 'both')	1	0.200000
('both', 'techniques')	1	1.000000
('techniques', 'we')	1	0.500000
('we', 'conduct')	1	0.500000
('conduct', 'a')	1	1.000000
('a', 'simulated')	1	0.333333
('simulated', 'study')	1	1.000000
('study', 'on')	1	1.000000
('on', 'eight')	1	0.333333
('eight', 'widely')	1	1.000000
('widely', 'used')	1	1.000000
('used', 'real')	1	0.250000
('real', 'time')	1	0.500000
('series', 'and')	1	0.166667
('and', 'compare')	1	0.100000
('compare', 'the')	1	1.000000
('performance', 'with')	1	0.250000
('with', 'some')	1	0.500000
('some', 'recently')	1	1.000000
('recently', 'developed')	1	1.000000
('developed', 'models')	1	1.000000
('models', '</s>')	1	1.000000
('<s>', 'Two')	1	0.111111
('Two', 'performance')	1	1.000000
('performance', 'measures')	1	0.250000
('measures', 'RSME')	1	1.000000
('RSME', 'and')	1	1.000000
('and', 'SMAPE')	1	0.100000
('SMAPE', 'are')	1	1.000000
('used', 'for')	1	0.250000
('for', 'performance')	1	0.333333
('performance', 'analysis')	1	0.250000
('analysis', 'and')	1	1.000000
('and', 'observed')	1	0.100000
('observed', 'better')	1	1.000000
('better', 'forecasting')	1	1.000000
('accuracy', 'by')	1	0.500000
('the', 'proposed')	1	0.111111
('proposed', 'model')	1	0.333333
('model', '.')	1	1.000000
('.', '</s>')	1	1.000000
