('<s>', 'Holoentropy')	1	0.100000
('Holoentropy', 'based')	2	0.666667
('based', 'Correlative')	2	0.500000
('Correlative', 'Naive')	2	1.000000
('Naive', 'Bayes')	3	1.000000
('Bayes', 'classifier')	3	1.000000
('classifier', 'and')	2	0.666667
('and', 'MapReduce')	2	0.222222
('MapReduce', 'model')	1	0.333333
('model', 'for')	1	1.000000
('for', 'classifying')	1	0.500000
('classifying', 'the')	1	1.000000
('the', 'big')	1	0.050000
('big', 'data')	2	0.666667
('data', '</s>')	2	0.285714
('</s>', '<s>')	9	0.900000
('<s>', 'Big')	1	0.100000
('Big', 'data')	1	1.000000
('data', 'is')	1	0.142857
('is', 'the')	1	0.166667
('the', 'recent')	1	0.050000
('recent', 'imminent')	1	1.000000
('imminent', 'technology')	1	1.000000
('technology', 'which')	1	1.000000
('which', 'can')	1	0.500000
('can', 'provide')	1	0.500000
('provide', 'large')	1	1.000000
('large', 'benefits')	1	1.000000
('benefits', 'to')	1	1.000000
('to', 'the')	1	0.142857
('the', 'business')	1	0.050000
('business', 'administration')	1	1.000000
('administration', '</s>')	1	1.000000
('<s>', 'Owing')	1	0.100000
('Owing', 'to')	1	1.000000
('to', 'such')	1	0.142857
('such', 'huge')	1	0.500000
('huge', 'volume')	1	1.000000
('volume', 'it')	1	1.000000
('it', 'becomes')	1	0.500000
('becomes', 'very')	1	1.000000
('very', 'complicated')	1	1.000000
('complicated', 'to')	1	1.000000
('to', 'ensure')	1	0.142857
('ensure', 'effective')	1	1.000000
('effective', 'analysis')	1	1.000000
('analysis', 'by')	1	1.000000
('by', 'the')	1	0.500000
('the', 'existing')	2	0.100000
('existing', 'techniques')	2	1.000000
('techniques', '</s>')	1	0.500000
('<s>', 'The')	4	0.400000
('The', 'complications')	1	0.250000
('complications', 'can')	1	1.000000
('can', 'be')	1	0.500000
('be', 'related')	1	1.000000
('related', 'to')	1	1.000000
('to', 'analyze')	1	0.142857
('analyze', 'capture')	1	1.000000
('capture', 'sharing')	1	1.000000
('sharing', 'storage')	1	1.000000
('storage', 'and')	1	1.000000
('and', 'visualization')	1	0.111111
('visualization', 'of')	1	1.000000
('of', 'the')	3	0.600000
('the', 'data')	2	0.100000
('<s>', 'To')	1	0.100000
('To', 'tackle')	1	1.000000
('tackle', 'these')	1	1.000000
('these', 'challenges')	1	1.000000
('challenges', 'a')	1	1.000000
('a', 'novel')	1	0.500000
('novel', 'classification')	1	1.000000
('classification', 'technique')	1	0.333333
('technique', 'using')	1	1.000000
('using', 'Holoentropy')	1	0.333333
('MapReduce', 'Model')	2	0.666667
('Model', 'HCNB-MRM')	1	0.500000
('HCNB-MRM', 'is')	3	0.750000
('is', 'proposed')	1	0.166667
('proposed', '</s>')	1	0.166667
('The', 'proposed')	2	0.500000
('proposed', 'HCNB')	2	0.333333
('HCNB', 'which')	1	0.500000
('which', 'is')	1	0.500000
('is', 'designed')	1	0.166667
('designed', 'by')	1	1.000000
('by', 'combining')	1	0.500000
('combining', 'the')	1	1.000000
('the', 'Holoentropy')	1	0.050000
('Holoentropy', 'function')	1	0.333333
('function', 'with')	1	1.000000
('with', 'the')	3	0.750000
('the', 'correlative')	1	0.050000
('correlative', 'based')	1	1.000000
('based', 'Naive')	1	0.250000
('classifier', 'deals')	1	0.333333
('deals', 'with')	1	1.000000
('with', 'both')	1	0.250000
('both', 'high-dimensional')	1	1.000000
('high-dimensional', 'data')	1	1.000000
('data', 'sets')	1	0.142857
('sets', 'as')	1	1.000000
('as', 'well')	1	0.333333
('well', 'as')	1	1.000000
('as', 'extensive')	1	0.333333
('extensive', 'datasets')	1	1.000000
('datasets', 'to')	1	1.000000
('to', 'improve')	1	0.142857
('improve', 'the')	1	1.000000
('the', 'benchmark')	1	0.050000
('benchmark', 'and')	1	1.000000
('and', 'classify')	1	0.111111
('classify', 'the')	1	1.000000
('data', 'based')	1	0.142857
('based', 'on')	1	0.250000
('on', 'dependent')	1	1.000000
('dependent', 'assumption')	1	1.000000
('assumption', '</s>')	1	1.000000
('<s>', 'Therefore')	1	0.100000
('Therefore', 'the')	1	1.000000
('the', 'proposed')	3	0.150000
('proposed', 'HCNB-MRM')	3	0.500000
('is', 'used')	1	0.166667
('used', 'to')	1	1.000000
('to', 'make')	1	0.142857
('make', 'the')	1	1.000000
('the', 'process')	1	0.050000
('process', 'simpler')	1	1.000000
('simpler', 'and')	1	1.000000
('and', 'to')	1	0.111111
('to', 'choose')	1	0.142857
('choose', 'the')	1	1.000000
('the', 'best')	1	0.050000
('best', 'features')	1	1.000000
('features', 'from')	1	1.000000
('from', 'big')	1	1.000000
('big', 'dataset')	1	0.333333
('dataset', '</s>')	1	0.333333
('HCNB', 'with')	1	0.500000
('the', 'MapReduce')	1	0.050000
('Model', 'maximizes')	1	0.500000
('maximizes', 'the')	1	1.000000
('the', 'performance')	1	0.050000
('performance', 'of')	2	1.000000
('of', 'big')	1	0.200000
('data', 'classification')	1	0.142857
('classification', 'using')	1	0.333333
('using', 'probability')	1	0.333333
('probability', 'index')	1	0.500000
('index', 'table')	1	1.000000
('table', 'and')	1	1.000000
('and', 'posterior')	1	0.111111
('posterior', 'probability')	1	1.000000
('probability', 'of')	1	0.500000
('the', 'testing')	1	0.050000
('testing', 'data')	1	1.000000
('data', 'samples')	1	0.142857
('samples', '</s>')	1	1.000000
('The', 'performance')	1	0.250000
('is', 'evaluated')	1	0.166667
('evaluated', 'using')	1	1.000000
('using', 'three')	1	0.333333
('three', 'metrics')	1	1.000000
('metrics', 'such')	1	1.000000
('such', 'as')	1	0.500000
('as', 'accuracy')	1	0.333333
('accuracy', 'sensitivity')	1	0.500000
('sensitivity', 'and')	1	1.000000
('and', 'specificity')	1	0.111111
('specificity', '</s>')	1	1.000000
('<s>', 'From')	1	0.100000
('From', 'the')	1	1.000000
('the', 'experimental')	1	0.050000
('experimental', 'results')	1	1.000000
('results', 'it')	1	1.000000
('it', 'is')	1	0.500000
('is', 'analyzed')	1	0.166667
('analyzed', 'that')	1	1.000000
('that', 'the')	1	1.000000
('HCNB-MRM', 'obtains')	1	0.250000
('obtains', 'a')	1	1.000000
('a', 'high')	1	0.500000
('high', 'classification')	1	1.000000
('classification', 'accuracy')	1	0.333333
('accuracy', 'of')	1	0.500000
('of', '93.5965%')	1	0.200000
('93.5965%', 'and')	1	1.000000
('and', '94.3369%')	1	0.111111
('94.3369%', 'for')	1	1.000000
('for', 'the')	1	0.500000
('the', 'localization')	1	0.050000
('localization', 'dataset')	1	1.000000
('dataset', 'and')	1	0.333333
('and', 'skin')	1	0.111111
('skin', 'dataset')	1	1.000000
('dataset', 'when')	1	0.333333
('when', 'compared')	1	1.000000
('compared', 'with')	1	1.000000
('techniques', '.')	1	0.500000
('.', '</s>')	1	1.000000
