('<s>', 'Extending')	1	0.200000
('Extending', 'a')	1	1.000000
('a', 'simple')	2	0.333333
('simple', 'genetic')	1	0.500000
('genetic', 'cooperative-competitive')	1	0.500000
('cooperative-competitive', 'learning')	1	0.500000
('learning', 'fuzzy')	1	0.500000
('fuzzy', 'classifier')	1	0.333333
('classifier', 'to')	2	1.000000
('to', 'low')	1	0.166667
('low', 'quality')	3	1.000000
('quality', 'datasets')	2	0.666667
('datasets', '</s>')	1	0.500000
('</s>', '<s>')	4	0.800000
('<s>', 'Exploiting')	1	0.200000
('Exploiting', 'the')	1	1.000000
('the', 'information')	1	0.166667
('information', 'in')	1	1.000000
('in', 'low')	1	0.333333
('datasets', 'has')	1	0.500000
('has', 'been')	1	1.000000
('been', 'recently')	1	1.000000
('recently', 'acknowledged')	1	1.000000
('acknowledged', 'as')	1	1.000000
('as', 'a')	1	1.000000
('a', 'new')	1	0.166667
('new', 'challenge')	1	1.000000
('challenge', 'in')	1	1.000000
('in', 'Genetic')	1	0.333333
('Genetic', 'Fuzzy')	2	1.000000
('Fuzzy', 'Systems')	1	0.500000
('Systems', '</s>')	1	1.000000
('<s>', 'Owing')	1	0.200000
('Owing', 'to')	1	1.000000
('to', 'this')	1	0.166667
('this', 'in')	1	0.500000
('in', 'this')	1	0.333333
('this', 'paper')	1	0.500000
('paper', 'we')	1	1.000000
('we', 'discuss')	1	0.500000
('discuss', 'the')	1	1.000000
('the', 'basic')	1	0.166667
('basic', 'principles')	1	1.000000
('principles', 'that')	1	0.500000
('that', 'govern')	1	0.250000
('govern', 'the')	1	1.000000
('the', 'extension')	1	0.166667
('extension', 'of')	1	1.000000
('of', 'a')	3	0.750000
('a', 'fuzzy')	1	0.166667
('fuzzy', 'rule')	1	0.333333
('rule', 'based')	1	1.000000
('based', 'classifier')	1	1.000000
('to', 'interval')	1	0.166667
('interval', 'and')	2	1.000000
('and', 'fuzzy')	1	0.333333
('fuzzy', 'data')	1	0.333333
('data', '</s>')	2	0.666667
('<s>', 'We')	1	0.200000
('We', 'have')	1	1.000000
('have', 'also')	1	1.000000
('also', 'applied')	1	1.000000
('applied', 'these')	1	1.000000
('these', 'principles')	1	1.000000
('principles', 'to')	1	0.500000
('to', 'the')	1	0.166667
('the', 'genetic')	1	0.166667
('genetic', 'learning')	1	0.500000
('learning', 'of')	1	0.500000
('simple', 'cooperative-competitive')	1	0.500000
('cooperative-competitive', 'algorithm')	1	0.500000
('algorithm', 'that')	1	1.000000
('that', 'becomes')	1	0.250000
('becomes', 'the')	1	1.000000
('the', 'first')	1	0.166667
('first', 'example')	1	1.000000
('example', 'of')	1	1.000000
('a', 'Genetic')	1	0.166667
('Fuzzy', 'Classifier')	1	0.500000
('Classifier', 'able')	1	1.000000
('able', 'to')	1	1.000000
('to', 'use')	1	0.166667
('use', 'low')	1	1.000000
('quality', 'data')	1	0.333333
('<s>', 'Additionally')	1	0.200000
('Additionally', 'we')	1	1.000000
('we', 'introduce')	1	0.500000
('introduce', 'a')	1	1.000000
('a', 'benchmark')	1	0.166667
('benchmark', 'comprising')	1	1.000000
('comprising', 'some')	1	1.000000
('some', 'synthetic')	1	1.000000
('synthetic', 'samples')	1	1.000000
('samples', 'and')	1	1.000000
('and', 'two')	1	0.333333
('two', 'real-world')	1	1.000000
('real-world', 'problems')	1	1.000000
('problems', 'that')	1	1.000000
('that', 'involve')	1	0.250000
('involve', 'interval')	1	1.000000
('and', 'fuzzy-valued')	1	0.333333
('fuzzy-valued', 'data')	1	1.000000
('data', 'that')	1	0.333333
('that', 'can')	1	0.250000
('can', 'be')	1	1.000000
('be', 'used')	1	1.000000
('used', 'to')	1	1.000000
('to', 'assess')	1	0.166667
('assess', 'future')	1	1.000000
('future', 'algorithms')	1	1.000000
('algorithms', 'of')	1	1.000000
('of', 'the')	1	0.250000
('the', 'same')	1	0.166667
('same', 'kind')	1	1.000000
('kind', '.')	1	1.000000
('.', '</s>')	1	1.000000
