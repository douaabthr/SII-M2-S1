('<s>', 'a')	2	0.153846
('a', 'novel')	2	0.250000
('novel', 'improv')	1	0.500000
('improv', 'predict')	1	1.000000
('predict', 'of')	2	0.500000
('of', 'protein')	2	0.285714
('protein', 'structur')	1	0.250000
('structur', 'class')	2	0.666667
('class', 'use')	1	0.500000
('use', 'deep')	1	0.500000
('deep', 'recurr')	1	0.333333
('recurr', 'neural')	1	0.500000
('neural', 'network')	1	1.000000
('network', '</s>')	1	0.333333
('</s>', '<s>')	12	0.923077
('<s>', 'for')	1	0.076923
('for', 'last')	1	0.090909
('last', 'few')	1	1.000000
('few', 'decad')	1	1.000000
('decad', 'sequenc')	1	1.000000
('sequenc', 'arrang')	1	0.333333
('arrang', 'of')	1	1.000000
('of', 'amino')	1	0.142857
('amino', 'acid')	2	1.000000
('acid', 'have')	1	0.500000
('have', 'been')	2	0.666667
('been', 'util')	1	0.500000
('util', 'for')	1	1.000000
('for', 'the')	3	0.272727
('the', 'predict')	1	0.100000
('protein', 'secondari')	2	0.500000
('secondari', 'structur')	2	1.000000
('structur', '</s>')	1	0.333333
('<s>', 'recent')	1	0.076923
('recent', 'method')	1	1.000000
('method', 'have')	1	0.333333
('have', 'appli')	1	0.333333
('appli', 'high')	1	0.500000
('high', 'dimension')	1	1.000000
('dimension', 'natur')	1	0.166667
('natur', 'languag')	1	1.000000
('languag', 'base')	1	1.000000
('base', 'featur')	1	0.333333
('featur', 'in')	1	0.250000
('in', 'machin')	1	0.142857
('machin', 'learn')	2	1.000000
('learn', 'model')	1	0.500000
('model', '</s>')	1	0.333333
('<s>', 'perform')	1	0.076923
('perform', 'measur')	1	0.500000
('measur', 'of')	1	1.000000
('of', 'machin')	1	0.142857
('learn', 'base')	1	0.500000
('base', 'model')	1	0.333333
('model', 'are')	1	0.333333
('are', 'signific')	1	0.500000
('signific', 'affect')	1	1.000000
('affect', 'by')	1	1.000000
('by', 'data')	1	1.000000
('data', 'size')	1	0.250000
('size', 'and')	1	0.200000
('and', 'data')	1	0.100000
('data', 'dimension')	1	0.250000
('dimension', '</s>')	1	0.166667
('<s>', 'it')	1	0.076923
('it', 'is')	1	1.000000
('is', 'a')	1	0.250000
('a', 'huge')	1	0.125000
('huge', 'challeng')	1	1.000000
('challeng', 'to')	1	1.000000
('to', 'develop')	1	0.250000
('develop', 'a')	1	1.000000
('a', 'generic')	1	0.125000
('generic', 'model')	1	1.000000
('model', 'which')	1	0.333333
('which', 'can')	1	1.000000
('can', 'be')	1	1.000000
('be', 'train')	1	1.000000
('train', 'to')	1	1.000000
('to', 'perform')	1	0.250000
('perform', 'both')	1	0.500000
('both', 'for')	1	0.250000
('for', 'small')	1	0.090909
('small', 'and')	2	0.500000
('and', 'larg')	3	0.300000
('larg', 'size')	3	1.000000
('size', 'dataset')	2	0.400000
('dataset', 'in')	1	0.333333
('in', 'a')	2	0.285714
('a', 'low')	2	0.250000
('low', 'dimension')	4	0.800000
('dimension', 'framework')	1	0.166667
('framework', '</s>')	1	1.000000
('<s>', 'in')	1	0.076923
('in', 'the')	1	0.142857
('the', 'present')	1	0.100000
('present', 'research')	1	1.000000
('research', 'we')	1	0.500000
('we', 'suggest')	1	0.333333
('suggest', 'a')	1	1.000000
('dimension', 'represent')	1	0.166667
('represent', 'for')	1	0.250000
('for', 'both')	2	0.181818
('both', 'small')	2	0.500000
('dataset', '</s>')	1	0.333333
('a', 'hybrid')	1	0.125000
('hybrid', 'space')	1	1.000000
('space', 'of')	1	0.500000
('of', 'atchley')	1	0.142857
('atchley', 's')	1	1.000000
('s', 'factor')	1	1.000000
('factor', 'ii')	1	1.000000
('ii', 'iv')	1	1.000000
('iv', 'v')	1	1.000000
('v', 'electron')	1	1.000000
('electron', 'ion')	1	1.000000
('ion', 'interact')	1	1.000000
('interact', 'potenti')	1	1.000000
('potenti', 'and')	1	1.000000
('and', 'skipgram')	1	0.100000
('skipgram', 'base')	1	1.000000
('base', 'word2vec')	1	0.333333
('word2vec', 'have')	1	1.000000
('been', 'employ')	1	0.500000
('employ', 'for')	1	1.000000
('for', 'amino')	1	0.090909
('acid', 'sequenc')	1	0.500000
('sequenc', 'represent')	1	0.333333
('represent', '</s>')	1	0.250000
('<s>', 'subsequ')	1	0.076923
('subsequ', 'stockwel')	1	1.000000
('stockwel', 'transform')	1	1.000000
('transform', 'is')	1	1.000000
('is', 'appli')	1	0.250000
('appli', 'to')	1	0.500000
('to', 'the')	1	0.250000
('the', 'represent')	1	0.100000
('represent', 'to')	1	0.250000
('to', 'preserv')	1	0.250000
('preserv', 'featur')	1	1.000000
('featur', 'both')	1	0.250000
('both', 'in')	1	0.250000
('in', 'time')	1	0.142857
('time', 'and')	1	0.333333
('and', 'frequenc')	1	0.100000
('frequenc', 'domain')	1	1.000000
('domain', '</s>')	1	1.000000
('<s>', 'final')	1	0.076923
('final', 'deep')	1	1.000000
('deep', 'gate')	1	0.333333
('gate', 'recurr')	1	1.000000
('recurr', 'network')	1	0.500000
('network', 'with')	1	0.333333
('with', 'dropout')	1	0.500000
('dropout', 'categorical-cross')	1	1.000000
('categorical-cross', 'entropi')	1	1.000000
('entropi', 'error')	1	1.000000
('error', 'estim')	1	1.000000
('estim', 'and')	1	1.000000
('and', 'adam')	1	0.100000
('adam', 'optim')	1	1.000000
('optim', 'is')	1	1.000000
('is', 'use')	1	0.250000
('use', 'for')	1	0.500000
('for', 'classif')	1	0.090909
('classif', 'purpos')	1	0.500000
('purpos', '</s>')	1	1.000000
('<s>', 'the')	3	0.230769
('the', 'introduc')	1	0.100000
('introduc', 'method')	1	1.000000
('method', 'result')	1	0.333333
('result', 'in')	1	1.000000
('in', 'better')	1	0.142857
('better', 'predict')	1	1.000000
('predict', 'accuraci')	1	0.250000
('accuraci', 'for')	2	1.000000
('small', '204,277')	1	0.250000
('204,277', 'and')	1	1.000000
('and', '498')	1	0.100000
('498', 'and')	1	0.500000
('size', 'pdb25')	1	0.200000
('pdb25', 'protein')	1	0.500000
('protein', '640')	1	0.250000
('640', 'and')	1	0.500000
('and', 'fc699')	1	0.100000
('fc699', 'bench')	1	0.500000
('bench', 'mark')	1	1.000000
('mark', 'data')	1	1.000000
('data', 'set')	2	0.500000
('set', 'of')	1	0.500000
('of', 'low')	1	0.142857
('low', 'sequenc')	1	0.200000
('sequenc', 'similar')	1	0.333333
('similar', '25')	1	1.000000
('25', '40%')	1	1.000000
('40%', '</s>')	1	1.000000
('the', 'obtain')	1	0.100000
('obtain', 'classif')	1	1.000000
('classif', 'accuraci')	1	0.500000
('for', 'pdb25')	1	0.090909
('pdb25', '640')	1	0.500000
('640', 'fc699')	1	0.500000
('fc699', '498')	1	0.500000
('498', '277')	1	0.500000
('277', '204')	1	1.000000
('204', 'dataset')	1	1.000000
('dataset', 'are')	1	0.333333
('are', '84.2%')	1	0.500000
('84.2%', '94.31%')	1	1.000000
('94.31%', '93.1%')	1	1.000000
('93.1%', '95.9%')	1	1.000000
('95.9%', '94.5%')	1	1.000000
('94.5%', 'and')	1	1.000000
('and', '85.36%')	1	0.100000
('85.36%', 'respect')	1	1.000000
('respect', '</s>')	1	1.000000
('the', 'major')	1	0.100000
('major', 'contribut')	1	1.000000
('contribut', 'in')	1	1.000000
('in', 'this')	1	0.142857
('this', 'research')	1	1.000000
('research', 'is')	1	0.500000
('is', 'that')	1	0.250000
('that', 'for')	1	1.000000
('the', 'first')	2	0.200000
('first', 'time')	2	1.000000
('time', 'we')	1	0.333333
('we', 'verifi')	1	0.333333
('verifi', 'the')	1	0.500000
('the', 'protein')	1	0.100000
('class', 'predict')	1	0.500000
('predict', 'in')	1	0.250000
('a', 'veri')	1	0.125000
('veri', 'low')	1	1.000000
('dimension', '18')	1	0.166667
('18', 'd')	1	1.000000
('d', 'featur')	1	1.000000
('featur', 'space')	1	0.250000
('space', 'with')	1	0.500000
('with', 'a')	1	0.500000
('novel', 'featur')	1	0.500000
('featur', 'represent')	1	0.250000
('represent', 'method')	1	0.250000
('method', '</s>')	1	0.333333
('<s>', 'second')	1	0.076923
('second', 'we')	1	1.000000
('we', 'also')	1	0.333333
('also', 'verifi')	1	1.000000
('verifi', 'for')	1	0.500000
('time', 'the')	1	0.333333
('the', 'behaviour')	1	0.100000
('behaviour', 'of')	1	1.000000
('of', 'deep')	1	0.142857
('deep', 'network')	1	0.333333
('network', 'for')	1	0.333333
('for', 'low')	1	0.090909
('dimension', 'small')	1	0.166667
('small', 'size')	1	0.250000
('size', 'data')	1	0.200000
('set', '.')	1	0.500000
('.', '</s>')	1	1.000000
