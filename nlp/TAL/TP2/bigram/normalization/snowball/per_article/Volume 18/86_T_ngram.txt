('<s>', 'a')	1	0.090909
('a', 'novel')	2	0.500000
('novel', 'fuzzy-entropi')	1	0.500000
('fuzzy-entropi', 'base')	1	1.000000
('base', 'onlin')	1	1.000000
('onlin', 'fuzzi')	2	0.666667
('fuzzi', 'c-mean')	5	0.833333
('c-mean', 'cluster')	1	0.200000
('cluster', 'algorithm')	1	0.111111
('algorithm', 'for')	2	0.285714
('for', 'massiv')	1	0.200000
('massiv', 'data')	1	0.500000
('data', '</s>')	2	0.666667
('</s>', '<s>')	10	0.909091
('<s>', 'due')	1	0.090909
('due', 'to')	1	1.000000
('to', 'the')	2	0.285714
('the', 'inadequaci')	1	0.058824
('inadequaci', 'of')	1	1.000000
('of', 'standard')	1	0.083333
('standard', 'cluster')	1	0.500000
('cluster', 'approach')	1	0.111111
('approach', 'for')	1	0.500000
('for', 'handl')	1	0.200000
('handl', 'extens')	1	1.000000
('extens', 'data')	1	1.000000
('data', 'consider')	1	0.333333
('consider', 'research')	1	1.000000
('research', 'has')	1	0.500000
('has', 'recent')	1	1.000000
('recent', 'focus')	1	1.000000
('focus', 'on')	2	1.000000
('on', 'cluster')	1	0.333333
('cluster', 'larg')	2	0.222222
('larg', 'and')	1	0.333333
('and', 'extrem')	1	0.250000
('extrem', 'larg')	1	1.000000
('larg', 'dataset')	1	0.333333
('dataset', '</s>')	1	0.200000
('<s>', 'specif')	1	0.090909
('specif', 'certain')	1	1.000000
('certain', 'variat')	1	1.000000
('variat', 'of')	2	1.000000
('of', 'the')	4	0.333333
('the', 'famous')	1	0.058824
('famous', 'fuzzi')	1	1.000000
('c-mean', 'algorithm')	2	0.400000
('algorithm', 'have')	1	0.142857
('have', 'been')	1	1.000000
('been', 'put')	1	1.000000
('put', 'forth')	1	1.000000
('forth', 'test')	1	1.000000
('test', 'techniqu')	1	1.000000
('techniqu', 'for')	1	0.333333
('for', 'segment')	1	0.200000
('segment', 'dataset')	1	1.000000
('dataset', 'and')	1	0.200000
('and', 'aggreg')	1	0.250000
('aggreg', 'the')	1	1.000000
('the', 'intermedi')	1	0.058824
('intermedi', 'cluster')	1	1.000000
('cluster', 'result')	2	0.222222
('result', '</s>')	1	0.500000
('<s>', 'among')	1	0.090909
('among', 'them')	1	1.000000
('them', 'the')	1	1.000000
('the', 'fuzzi')	2	0.117647
('c-mean', 'onlin')	1	0.200000
('onlin', 'techniqu')	1	0.333333
('techniqu', 'is')	1	0.333333
('is', 'one')	1	0.500000
('one', 'of')	1	1.000000
('the', 'most')	1	0.058824
('most', 'use')	1	1.000000
('use', 'for')	1	1.000000
('for', 'cluster')	1	0.200000
('larg', 'amount')	1	0.333333
('amount', 'of')	1	1.000000
('of', 'data')	1	0.083333
('<s>', 'it')	1	0.090909
('it', 'split')	1	0.500000
('split', 'the')	1	1.000000
('the', 'dataset')	1	0.058824
('dataset', 'into')	1	0.200000
('into', 'equal-s')	1	0.500000
('equal-s', 'subset')	1	1.000000
('subset', 'or')	1	1.000000
('or', 'chunk')	1	1.000000
('chunk', 'and')	1	0.500000
('and', 'assign')	1	0.250000
('assign', 'a')	1	1.000000
('a', 'weight')	1	0.250000
('weight', 'to')	1	0.500000
('to', 'each')	1	0.142857
('each', 'chunk')	1	0.500000
('chunk', 'depend')	1	0.500000
('depend', 'on')	1	1.000000
('on', 'the')	1	0.333333
('the', 'membership')	1	0.058824
('membership', 'degre')	1	1.000000
('degre', 'per')	1	1.000000
('per', 'cluster')	1	1.000000
('cluster', '</s>')	2	0.222222
('<s>', 'this')	1	0.090909
('this', 'studi')	1	0.500000
('studi', 'introduc')	1	1.000000
('introduc', 'a')	1	1.000000
('novel', 'variat')	1	0.500000
('the', 'onlin')	1	0.058824
('c-mean', 'ofcm')	1	0.200000
('ofcm', 'algorithm')	1	0.500000
('algorithm', 'design')	1	0.142857
('design', 'to')	1	1.000000
('to', 'boost')	1	0.142857
('boost', 'it')	1	1.000000
('it', 'perform')	1	0.500000
('perform', '</s>')	1	0.500000
('<s>', 'our')	1	0.090909
('our', 'propos')	1	0.500000
('propos', 'method')	1	0.333333
('method', 'integr')	1	1.000000
('integr', 'a')	1	1.000000
('a', 'cluster')	1	0.250000
('cluster', 'compact')	1	0.111111
('compact', 'measur')	1	1.000000
('measur', 'into')	1	1.000000
('into', 'the')	1	0.500000
('the', 'weight')	1	0.058824
('weight', 'attribut')	1	0.500000
('attribut', 'process')	1	1.000000
('process', 'quantifi')	1	1.000000
('quantifi', 'by')	1	1.000000
('by', 'the')	1	0.500000
('fuzzi', 'entropi')	1	0.166667
('entropi', 'of')	1	1.000000
('of', 'each')	1	0.083333
('each', 'cluster')	1	0.500000
('<s>', 'compar')	1	0.090909
('compar', 'experi')	1	0.333333
('experi', 'conduct')	1	1.000000
('conduct', 'across')	1	1.000000
('across', 'divers')	1	1.000000
('divers', 'classif')	1	1.000000
('classif', 'dataset')	1	1.000000
('dataset', 'of')	1	0.200000
('of', 'vari')	1	0.083333
('vari', 'scale')	1	1.000000
('scale', 'demonstr')	1	1.000000
('demonstr', 'that')	1	1.000000
('that', 'the')	1	0.500000
('the', 'propos')	2	0.117647
('propos', 'algorithm')	2	0.666667
('algorithm', 'signific')	1	0.142857
('signific', 'improv')	1	1.000000
('improv', 'the')	1	1.000000
('the', 'accuraci')	1	0.058824
('accuraci', 'of')	1	1.000000
('of', 'cluster')	1	0.083333
('result', 'when')	1	0.500000
('when', 'compar')	1	1.000000
('compar', 'to')	2	0.666667
('the', 'standard')	1	0.058824
('standard', 'ofcm')	1	0.500000
('ofcm', '</s>')	1	0.500000
('<s>', 'crucial')	1	0.090909
('crucial', 'this')	1	1.000000
('this', 'enhanc')	1	0.500000
('enhanc', 'is')	1	1.000000
('is', 'achiev')	1	0.500000
('achiev', 'without')	1	1.000000
('without', 'increas')	1	1.000000
('increas', 'the')	1	1.000000
('the', 'comput')	1	0.058824
('comput', 'complex')	1	1.000000
('complex', 'of')	1	1.000000
('the', 'algorithm')	1	0.058824
('algorithm', '</s>')	1	0.142857
('<s>', 'furthermor')	1	0.090909
('furthermor', 'our')	1	1.000000
('our', 'approach')	1	0.500000
('approach', 'yield')	1	0.500000
('yield', 'perform')	1	1.000000
('perform', 'compar')	1	0.500000
('to', 'that')	1	0.142857
('that', 'of')	1	0.500000
('of', 'heurist')	1	0.083333
('heurist', 'fuzzi')	1	1.000000
('algorithm', 'while')	1	0.142857
('while', 'offer')	1	1.000000
('offer', 'the')	1	1.000000
('the', 'distinct')	1	0.058824
('distinct', 'advantag')	1	1.000000
('advantag', 'of')	1	1.000000
('of', 'shorter')	1	0.083333
('shorter', 'execut')	1	1.000000
('execut', 'time')	1	1.000000
('time', '</s>')	1	1.000000
('<s>', 'futur')	1	0.090909
('futur', 'research')	1	1.000000
('research', 'will')	1	0.500000
('will', 'focus')	1	1.000000
('on', 'explor')	1	0.333333
('explor', 'featur')	1	1.000000
('featur', 'select')	1	0.500000
('select', 'and')	1	1.000000
('and', 'reduct')	1	0.250000
('reduct', 'techniqu')	1	1.000000
('techniqu', 'to')	1	0.333333
('to', 'adapt')	1	0.142857
('adapt', 'the')	1	1.000000
('for', 'effect')	1	0.200000
('effect', 'applic')	1	1.000000
('applic', 'to')	1	1.000000
('to', 'massiv')	1	0.142857
('massiv', 'dataset')	1	0.500000
('dataset', 'character')	1	0.200000
('character', 'by')	1	1.000000
('by', 'an')	1	0.500000
('an', 'except')	1	1.000000
('except', 'high')	1	1.000000
('high', 'number')	1	1.000000
('number', 'of')	1	1.000000
('of', 'featur')	1	0.083333
('featur', '.')	1	0.500000
('.', '</s>')	1	1.000000
