('<s>', 'a')	1	0.100000
('a', 'new')	1	0.200000
('new', 'big')	1	1.000000
('big', 'data')	1	1.000000
('data', 'approach')	1	0.250000
('approach', 'for')	1	0.500000
('for', 'topic')	1	0.250000
('topic', 'classif')	2	1.000000
('classif', 'and')	1	0.333333
('and', 'sentiment')	1	0.111111
('sentiment', 'analysi')	4	0.800000
('analysi', 'of')	1	0.250000
('of', 'twitter')	1	0.142857
('twitter', 'data')	1	0.200000
('data', '</s>')	1	0.250000
('</s>', '<s>')	9	0.900000
('<s>', 'twitter')	1	0.100000
('twitter', 'is')	3	0.600000
('is', 'a')	1	0.125000
('a', 'major')	2	0.400000
('major', 'micro-blog')	1	0.500000
('micro-blog', 'servic')	1	1.000000
('servic', 'with')	1	1.000000
('with', 'million')	1	0.500000
('million', 'of')	1	1.000000
('of', 'activ')	1	0.142857
('activ', 'user')	1	1.000000
('user', '</s>')	1	0.500000
('<s>', 'these')	1	0.100000
('these', 'user')	1	1.000000
('user', 'use')	1	0.500000
('use', 'twitter')	1	0.500000
('twitter', 'to')	1	0.200000
('to', 'post')	1	0.250000
('post', 'statu')	1	1.000000
('statu', 'messag')	1	1.000000
('messag', 'call')	1	1.000000
('call', 'tweet')	1	1.000000
('tweet', 'and')	1	0.333333
('and', 'share')	1	0.111111
('share', 'their')	1	1.000000
('their', 'opinion')	1	1.000000
('opinion', 'use')	1	0.500000
('use', 'hash')	1	0.500000
('hash', 'tag')	1	1.000000
('tag', 'on')	1	1.000000
('on', 'variou')	1	1.000000
('variou', 'event')	1	1.000000
('event', '</s>')	1	1.000000
('<s>', 'henc')	1	0.100000
('henc', 'twitter')	1	1.000000
('is', 'consid')	1	0.125000
('consid', 'a')	1	1.000000
('major', 'real')	1	0.500000
('real', 'time')	1	1.000000
('time', 'stream')	1	0.333333
('stream', 'sourc')	1	1.000000
('sourc', 'and')	1	1.000000
('and', 'one')	1	0.111111
('one', 'of')	1	1.000000
('of', 'an')	1	0.142857
('an', 'effect')	1	0.500000
('effect', 'and')	1	1.000000
('and', 'accur')	1	0.111111
('accur', 'indic')	1	1.000000
('indic', 'of')	1	1.000000
('of', 'opinion')	1	0.142857
('opinion', '</s>')	1	0.500000
('<s>', 'the')	2	0.200000
('the', 'amount')	1	0.200000
('amount', 'of')	1	1.000000
('of', 'data')	1	0.142857
('data', 'gener')	1	0.250000
('gener', 'by')	1	1.000000
('by', 'twitter')	1	0.500000
('is', 'huge')	1	0.125000
('huge', 'and')	1	1.000000
('and', 'it')	1	0.111111
('it', 'is')	1	1.000000
('is', 'difficult')	1	0.125000
('difficult', 'to')	1	1.000000
('to', 'scan')	1	0.250000
('scan', 'entir')	1	1.000000
('entir', 'data')	1	1.000000
('data', 'manual')	1	0.250000
('manual', '</s>')	1	1.000000
('<s>', 'thi')	1	0.100000
('thi', 'paper')	1	1.000000
('paper', 'propos')	1	1.000000
('propos', 'a')	1	0.333333
('a', 'hybrid')	1	0.200000
('hybrid', 'lexicon-na')	1	1.000000
('lexicon-na', 'bayesian')	1	1.000000
('bayesian', 'classifi')	2	1.000000
('classifi', 'hl-nbc')	1	0.333333
('hl-nbc', 'method')	2	1.000000
('method', 'for')	1	0.200000
('for', 'sentiment')	1	0.250000
('analysi', '</s>')	1	0.250000
('<s>', 'in')	1	0.100000
('in', 'addit')	1	0.250000
('addit', 'to')	1	1.000000
('to', 'that')	1	0.250000
('that', 'sentiment')	1	1.000000
('analysi', 'engin')	1	0.250000
('engin', 'is')	1	1.000000
('is', 'preced')	1	0.125000
('preced', 'by')	1	1.000000
('by', 'topic')	1	0.500000
('classif', 'which')	1	0.333333
('which', 'classifi')	1	0.500000
('classifi', 'tweet')	1	0.333333
('tweet', 'into')	1	0.333333
('into', 'differ')	1	1.000000
('differ', 'categori')	1	0.500000
('categori', 'and')	1	1.000000
('and', 'filter')	1	0.111111
('filter', 'irrelev')	1	1.000000
('irrelev', 'tweet')	1	1.000000
('tweet', '</s>')	1	0.333333
('the', 'propos')	2	0.400000
('propos', 'method')	1	0.333333
('method', 'is')	1	0.200000
('is', 'compar')	2	0.250000
('compar', 'with')	1	0.333333
('with', 'lexicon')	1	0.500000
('lexicon', 'naïv')	1	1.000000
('naïv', 'bayesian')	1	1.000000
('classifi', 'for')	1	0.333333
('for', 'uni-gram')	1	0.250000
('uni-gram', 'and')	1	1.000000
('and', 'bi-gram')	1	0.111111
('bi-gram', 'featur')	1	1.000000
('featur', '</s>')	1	1.000000
('<s>', 'out')	1	0.100000
('out', 'of')	1	1.000000
('of', 'the')	1	0.142857
('the', 'differ')	1	0.200000
('differ', 'approach')	1	0.500000
('approach', 'the')	1	0.500000
('propos', 'hl-nbc')	1	0.333333
('method', 'doe')	1	0.200000
('doe', 'sentiment')	1	1.000000
('sentiment', 'classif')	1	0.200000
('classif', 'in')	1	0.333333
('in', 'an')	1	0.250000
('an', 'improv')	1	0.500000
('improv', 'way')	1	0.500000
('way', 'and')	1	1.000000
('and', 'give')	1	0.111111
('give', 'accuraci')	1	1.000000
('accuraci', 'of')	1	1.000000
('of', '82%')	1	0.142857
('82%', 'which')	1	1.000000
('which', 'is')	1	0.500000
('compar', 'better')	1	0.333333
('better', 'than')	1	1.000000
('than', 'other')	1	1.000000
('other', 'method')	1	1.000000
('method', '</s>')	1	0.200000
('<s>', 'also')	1	0.100000
('also', 'the')	1	1.000000
('the', 'sentiment')	1	0.200000
('analysi', 'is')	1	0.250000
('is', 'perform')	1	0.125000
('perform', 'in')	1	1.000000
('in', 'a')	1	0.250000
('a', 'shorter')	1	0.200000
('shorter', 'time')	1	1.000000
('time', 'compar')	1	0.333333
('compar', 'to')	1	0.333333
('to', 'tradit')	1	0.250000
('tradit', 'method')	1	1.000000
('method', 'and')	1	0.200000
('and', 'achiev')	1	0.111111
('achiev', '93%')	1	1.000000
('93%', 'improv')	1	1.000000
('improv', 'in')	1	0.500000
('in', 'process')	1	0.250000
('process', 'time')	1	1.000000
('time', 'for')	1	0.333333
('for', 'larger')	1	0.250000
('larger', 'dataset')	1	1.000000
('dataset', '.')	1	1.000000
('.', '</s>')	1	1.000000
