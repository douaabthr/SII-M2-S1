('<s>', 'A', 'novel')	1	0.500000
('A', 'novel', 'improved')	1	1.000000
('novel', 'improved', 'prediction')	1	1.000000
('improved', 'prediction', 'of')	1	1.000000
('prediction', 'of', 'protein')	2	1.000000
('of', 'protein', 'structural')	1	0.500000
('protein', 'structural', 'class')	1	1.000000
('structural', 'class', 'using')	1	0.500000
('class', 'using', 'deep')	1	1.000000
('using', 'deep', 'recurrent')	1	1.000000
('deep', 'recurrent', 'neural')	1	1.000000
('recurrent', 'neural', 'network')	1	1.000000
('neural', 'network', '</s>')	1	1.000000
('network', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'For')	1	0.083333
('<s>', 'For', 'last')	1	1.000000
('For', 'last', 'few')	1	1.000000
('last', 'few', 'decades')	1	1.000000
('few', 'decades', 'sequence')	1	1.000000
('decades', 'sequence', 'arrangement')	1	1.000000
('sequence', 'arrangement', 'of')	1	1.000000
('arrangement', 'of', 'amino')	1	1.000000
('of', 'amino', 'acids')	1	1.000000
('amino', 'acids', 'have')	1	1.000000
('acids', 'have', 'been')	1	1.000000
('have', 'been', 'utilized')	1	0.500000
('been', 'utilized', 'for')	1	1.000000
('utilized', 'for', 'the')	1	1.000000
('for', 'the', 'prediction')	1	0.333333
('the', 'prediction', 'of')	1	1.000000
('of', 'protein', 'secondary')	1	0.500000
('protein', 'secondary', 'structure')	1	0.500000
('secondary', 'structure', '</s>')	1	1.000000
('structure', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'Recent')	1	0.083333
('<s>', 'Recent', 'methods')	1	1.000000
('Recent', 'methods', 'have')	1	1.000000
('methods', 'have', 'applied')	1	1.000000
('have', 'applied', 'high')	1	1.000000
('applied', 'high', 'dimensional')	1	1.000000
('high', 'dimensional', 'natural')	1	1.000000
('dimensional', 'natural', 'language')	1	1.000000
('natural', 'language', 'based')	1	1.000000
('language', 'based', 'features')	1	1.000000
('based', 'features', 'in')	1	1.000000
('features', 'in', 'machine')	1	1.000000
('in', 'machine', 'learning')	1	1.000000
('machine', 'learning', 'models')	1	0.500000
('learning', 'models', '</s>')	1	1.000000
('models', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'Performance')	1	0.083333
('<s>', 'Performance', 'measures')	1	1.000000
('Performance', 'measures', 'of')	1	1.000000
('measures', 'of', 'machine')	1	1.000000
('of', 'machine', 'learning')	1	1.000000
('machine', 'learning', 'based')	1	0.500000
('learning', 'based', 'models')	1	1.000000
('based', 'models', 'are')	1	1.000000
('models', 'are', 'significantly')	1	1.000000
('are', 'significantly', 'affected')	1	1.000000
('significantly', 'affected', 'by')	1	1.000000
('affected', 'by', 'data')	1	1.000000
('by', 'data', 'size')	1	1.000000
('data', 'size', 'and')	1	1.000000
('size', 'and', 'data')	1	1.000000
('and', 'data', 'dimensionality')	1	1.000000
('data', 'dimensionality', '</s>')	1	1.000000
('dimensionality', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'It')	1	0.083333
('<s>', 'It', 'is')	1	1.000000
('It', 'is', 'a')	1	1.000000
('is', 'a', 'huge')	1	1.000000
('a', 'huge', 'challenge')	1	1.000000
('huge', 'challenge', 'to')	1	1.000000
('challenge', 'to', 'develop')	1	1.000000
('to', 'develop', 'a')	1	1.000000
('develop', 'a', 'generic')	1	1.000000
('a', 'generic', 'model')	1	1.000000
('generic', 'model', 'which')	1	1.000000
('model', 'which', 'can')	1	1.000000
('which', 'can', 'be')	1	1.000000
('can', 'be', 'trained')	1	1.000000
('be', 'trained', 'to')	1	1.000000
('trained', 'to', 'perform')	1	1.000000
('to', 'perform', 'both')	1	1.000000
('perform', 'both', 'for')	1	1.000000
('both', 'for', 'small')	1	1.000000
('for', 'small', 'and')	1	1.000000
('small', 'and', 'large')	2	1.000000
('and', 'large', 'sized')	3	1.000000
('large', 'sized', 'datasets')	2	0.666667
('sized', 'datasets', 'in')	1	0.500000
('datasets', 'in', 'a')	1	1.000000
('in', 'a', 'low')	1	0.500000
('a', 'low', 'dimensional')	2	1.000000
('low', 'dimensional', 'framework')	1	0.250000
('dimensional', 'framework', '</s>')	1	1.000000
('framework', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'In')	1	0.083333
('<s>', 'In', 'the')	1	1.000000
('In', 'the', 'present')	1	1.000000
('the', 'present', 'research')	1	1.000000
('present', 'research', 'we')	1	1.000000
('research', 'we', 'suggest')	1	1.000000
('we', 'suggest', 'a')	1	1.000000
('suggest', 'a', 'low')	1	1.000000
('low', 'dimensional', 'representation')	1	0.250000
('dimensional', 'representation', 'for')	1	1.000000
('representation', 'for', 'both')	1	1.000000
('for', 'both', 'small')	2	1.000000
('both', 'small', 'and')	1	0.500000
('sized', 'datasets', '</s>')	1	0.500000
('datasets', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'A')	1	0.083333
('<s>', 'A', 'hybrid')	1	0.500000
('A', 'hybrid', 'space')	1	1.000000
('hybrid', 'space', 'of')	1	1.000000
('space', 'of', 'Atchley')	1	1.000000
('of', 'Atchley', 's')	1	1.000000
('Atchley', 's', 'factors')	1	1.000000
('s', 'factors', 'II')	1	1.000000
('factors', 'II', 'IV')	1	1.000000
('II', 'IV', 'V')	1	1.000000
('IV', 'V', 'electron')	1	1.000000
('V', 'electron', 'ion')	1	1.000000
('electron', 'ion', 'interaction')	1	1.000000
('ion', 'interaction', 'potential')	1	1.000000
('interaction', 'potential', 'and')	1	1.000000
('potential', 'and', 'SkipGram')	1	1.000000
('and', 'SkipGram', 'based')	1	1.000000
('SkipGram', 'based', 'word2vec')	1	1.000000
('based', 'word2vec', 'have')	1	1.000000
('word2vec', 'have', 'been')	1	1.000000
('have', 'been', 'employed')	1	0.500000
('been', 'employed', 'for')	1	1.000000
('employed', 'for', 'amino')	1	1.000000
('for', 'amino', 'acid')	1	1.000000
('amino', 'acid', 'sequence')	1	1.000000
('acid', 'sequence', 'representation')	1	1.000000
('sequence', 'representation', '</s>')	1	1.000000
('representation', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'Subsequently')	1	0.083333
('<s>', 'Subsequently', 'Stockwell')	1	1.000000
('Subsequently', 'Stockwell', 'transformation')	1	1.000000
('Stockwell', 'transformation', 'is')	1	1.000000
('transformation', 'is', 'applied')	1	1.000000
('is', 'applied', 'to')	1	1.000000
('applied', 'to', 'the')	1	1.000000
('to', 'the', 'representation')	1	1.000000
('the', 'representation', 'to')	1	1.000000
('representation', 'to', 'preserve')	1	1.000000
('to', 'preserve', 'features')	1	1.000000
('preserve', 'features', 'both')	1	1.000000
('features', 'both', 'in')	1	1.000000
('both', 'in', 'time')	1	1.000000
('in', 'time', 'and')	1	1.000000
('time', 'and', 'frequency')	1	1.000000
('and', 'frequency', 'domains')	1	1.000000
('frequency', 'domains', '</s>')	1	1.000000
('domains', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'Finally')	1	0.083333
('<s>', 'Finally', 'deep')	1	1.000000
('Finally', 'deep', 'gated')	1	1.000000
('deep', 'gated', 'recurrent')	1	1.000000
('gated', 'recurrent', 'network')	1	1.000000
('recurrent', 'network', 'with')	1	1.000000
('network', 'with', 'dropout')	1	1.000000
('with', 'dropout', 'categorical-cross')	1	1.000000
('dropout', 'categorical-cross', 'entropy')	1	1.000000
('categorical-cross', 'entropy', 'error')	1	1.000000
('entropy', 'error', 'estimation')	1	1.000000
('error', 'estimation', 'and')	1	1.000000
('estimation', 'and', 'Adam')	1	1.000000
('and', 'Adam', 'optimization')	1	1.000000
('Adam', 'optimization', 'is')	1	1.000000
('optimization', 'is', 'used')	1	1.000000
('is', 'used', 'for')	1	1.000000
('used', 'for', 'classification')	1	1.000000
('for', 'classification', 'purpose')	1	1.000000
('classification', 'purpose', '</s>')	1	1.000000
('purpose', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'The')	3	0.250000
('<s>', 'The', 'introduced')	1	0.333333
('The', 'introduced', 'method')	1	1.000000
('introduced', 'method', 'results')	1	1.000000
('method', 'results', 'in')	1	1.000000
('results', 'in', 'better')	1	1.000000
('in', 'better', 'prediction')	1	1.000000
('better', 'prediction', 'accuracies')	1	1.000000
('prediction', 'accuracies', 'for')	1	1.000000
('accuracies', 'for', 'both')	1	0.500000
('both', 'small', '204,277')	1	0.500000
('small', '204,277', 'and')	1	1.000000
('204,277', 'and', '498')	1	1.000000
('and', '498', 'and')	1	1.000000
('498', 'and', 'large')	1	1.000000
('large', 'sized', 'PDB25')	1	0.333333
('sized', 'PDB25', 'Protein')	1	1.000000
('PDB25', 'Protein', '640')	1	1.000000
('Protein', '640', 'and')	1	1.000000
('640', 'and', 'FC699')	1	1.000000
('and', 'FC699', 'bench')	1	1.000000
('FC699', 'bench', 'mark')	1	1.000000
('bench', 'mark', 'data')	1	1.000000
('mark', 'data', 'sets')	1	1.000000
('data', 'sets', 'of')	1	0.500000
('sets', 'of', 'low')	1	1.000000
('of', 'low', 'sequence')	1	1.000000
('low', 'sequence', 'similarity')	1	1.000000
('sequence', 'similarity', '25')	1	1.000000
('similarity', '25', '40%')	1	1.000000
('25', '40%', '</s>')	1	1.000000
('40%', '</s>', '<s>')	1	1.000000
('<s>', 'The', 'obtained')	1	0.333333
('The', 'obtained', 'classification')	1	1.000000
('obtained', 'classification', 'accuracies')	1	1.000000
('classification', 'accuracies', 'for')	1	1.000000
('accuracies', 'for', 'PDB25')	1	0.500000
('for', 'PDB25', '640')	1	1.000000
('PDB25', '640', 'FC699')	1	1.000000
('640', 'FC699', '498')	1	1.000000
('FC699', '498', '277')	1	1.000000
('498', '277', '204')	1	1.000000
('277', '204', 'datasets')	1	1.000000
('204', 'datasets', 'are')	1	1.000000
('datasets', 'are', '84.2%')	1	1.000000
('are', '84.2%', '94.31%')	1	1.000000
('84.2%', '94.31%', '93.1%')	1	1.000000
('94.31%', '93.1%', '95.9%')	1	1.000000
('93.1%', '95.9%', '94.5%')	1	1.000000
('95.9%', '94.5%', 'and')	1	1.000000
('94.5%', 'and', '85.36%')	1	1.000000
('and', '85.36%', 'respectively')	1	1.000000
('85.36%', 'respectively', '</s>')	1	1.000000
('respectively', '</s>', '<s>')	1	1.000000
('<s>', 'The', 'major')	1	0.333333
('The', 'major', 'contributions')	1	1.000000
('major', 'contributions', 'in')	1	1.000000
('contributions', 'in', 'this')	1	1.000000
('in', 'this', 'research')	1	1.000000
('this', 'research', 'is')	1	1.000000
('research', 'is', 'that')	1	1.000000
('is', 'that', 'for')	1	1.000000
('that', 'for', 'the')	1	1.000000
('for', 'the', 'first')	2	0.666667
('the', 'first', 'time')	2	1.000000
('first', 'time', 'we')	1	0.500000
('time', 'we', 'verify')	1	1.000000
('we', 'verify', 'the')	1	1.000000
('verify', 'the', 'protein')	1	1.000000
('the', 'protein', 'secondary')	1	1.000000
('protein', 'secondary', 'structural')	1	0.500000
('secondary', 'structural', 'class')	1	1.000000
('structural', 'class', 'prediction')	1	0.500000
('class', 'prediction', 'in')	1	1.000000
('prediction', 'in', 'a')	1	1.000000
('in', 'a', 'very')	1	0.500000
('a', 'very', 'low')	1	1.000000
('very', 'low', 'dimensional')	1	1.000000
('low', 'dimensional', '18')	1	0.250000
('dimensional', '18', 'D')	1	1.000000
('18', 'D', 'feature')	1	1.000000
('D', 'feature', 'space')	1	1.000000
('feature', 'space', 'with')	1	1.000000
('space', 'with', 'a')	1	1.000000
('with', 'a', 'novel')	1	1.000000
('a', 'novel', 'feature')	1	1.000000
('novel', 'feature', 'representation')	1	1.000000
('feature', 'representation', 'method')	1	1.000000
('representation', 'method', '</s>')	1	1.000000
('method', '</s>', '<s>')	1	1.000000
('</s>', '<s>', 'Secondly')	1	0.083333
('<s>', 'Secondly', 'we')	1	1.000000
('Secondly', 'we', 'also')	1	1.000000
('we', 'also', 'verify')	1	1.000000
('also', 'verify', 'for')	1	1.000000
('verify', 'for', 'the')	1	1.000000
('first', 'time', 'the')	1	0.500000
('time', 'the', 'behaviour')	1	1.000000
('the', 'behaviour', 'of')	1	1.000000
('behaviour', 'of', 'deep')	1	1.000000
('of', 'deep', 'networks')	1	1.000000
('deep', 'networks', 'for')	1	1.000000
('networks', 'for', 'low')	1	1.000000
('for', 'low', 'dimensional')	1	1.000000
('low', 'dimensional', 'small')	1	0.250000
('dimensional', 'small', 'sized')	1	1.000000
('small', 'sized', 'data')	1	1.000000
('sized', 'data', 'sets')	1	1.000000
('data', 'sets', '.')	1	0.500000
('sets', '.', '</s>')	1	1.000000
