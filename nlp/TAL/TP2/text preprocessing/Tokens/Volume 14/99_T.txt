<s>
Stochastic
gradient-CAViaR-based
deep
belief
network
for
text
categorization
</s>
<s>
Text
categorization
is
defined
as
the
process
of
assigning
tags
to
text
according
to
its
content
</s>
<s>
Some
of
the
text
classification
approaches
are
document
organization
spam
email
filtering
and
news
groupings
</s>
<s>
This
paper
introduces
stochastic
gradient-CAViaR-based
deep
belief
networks
for
text
categorization
</s>
<s>
The
overall
procedure
of
the
proposed
approach
involves
four
steps
such
as
pre-processing
feature
extraction
feature
selection
and
text
categorization
</s>
<s>
At
first
the
pre-processing
is
carried
out
from
the
input
data
based
on
stemming
stop-word
removal
and
then
the
feature
extraction
is
performed
using
a
vector
space
model
</s>
<s>
Once
the
extraction
is
done
the
feature
selection
is
carried
out
based
on
entropy
</s>
<s>
Subsequently
the
selected
features
are
given
to
the
text
categorization
step
</s>
<s>
Here
the
text
categorization
is
done
using
the
proposed
SG-CAV-based
deep
belief
networks
SG-CAV-based
DBN
</s>
<s>
The
proposed
SG-CAV
is
used
to
train
the
DBN
which
is
designed
by
combining
conditional
autoregressive
value
at
risk
and
stochastic
gradient
descent
</s>
<s>
The
performance
of
the
proposed
SGCAV
DBN
is
evaluated
based
on
the
metrics
such
as
recall
precision
F-measure
and
accuracy
</s>
<s>
Also
the
performance
of
the
proposed
method
is
compared
with
the
existing
methods
such
as
Naive
Bayes
K-nearest
neighbours
support
vector
machine
and
deep
belief
network
DBN
</s>
<s>
From
the
analysis
it
is
depicted
that
the
proposed
SGCAV
DBN
method
achieves
the
maximal
precision
of
0.78
the
maximal
recall
of
0.78
maximal
F-measure
of
0.78
and
the
maximal
accuracy
of
0.95
</s>
<s>
Among
the
existing
methods
DBN
achieves
the
maximum
precision
recall
F-measure
and
accuracy
for
20
Newsgroup
database
and
Reuter
database
</s>
<s>
The
performance
of
the
proposed
system
is
10.98%
11.54%
11.538%
and
18.33%
higher
than
the
precision
recall
F-measure
and
accuracy
of
the
DBN
for
20
Newsgroup
database
and
2.38%
2.38%
2.37%
and
0.21%
higher
than
the
precision
recall
F-measure
and
accuracy
of
the
DBN
for
Reuter
database
.
</s>