<s>
Fast
implementation
of
extreme
learning
machine-based
directRanker
for
surrogate-assisted
evolutionary
algorithms
</s>
<s>
Surrogate-assisted
evolutionary
algorithms
SAEAs
have
been
widely
used
to
solve
computationally
expensive
optimization
problems
</s>
<s>
The
extreme
learning
machine-based
DirectRanker
ELDR
is
a
single-layer
feed-forward
neural
network
surrogate
model
designed
for
SAEAs
</s>
<s>
ELDR
estimates
the
superiority
of
two
solutions
with
a
high
estimation
accuracy
even
in
high-dimensional
problems
</s>
<s>
However
ELDR
requires
a
long
computation
time
as
the
problem
dimensionality
and
the
number
of
hidden
neurons
increase
thus
making
it
difficult
to
apply
it
to
high-dimensional
problems
</s>
<s>
A
surrogate
model
should
be
computationally
efficient
and
enable
rapid
fitness
estimations
</s>
<s>
Therefore
this
paper
proposes
a
fast
implementation
technique
i.e.
fast
version
ELDR
fELDR
that
achieves
mathematically
equivalent
learning
results
with
low
computational
complexity
</s>
<s>
Additionally
this
paper
proposes
a
pointwise
score
function
to
render
the
prediction
results
reusable
</s>
<s>
The
experimental
results
confirmed
the
effectiveness
of
fELDR
when
compared
with
the
original
ELDR
</s>
<s>
The
learning
results
of
the
proposed
fELDR
were
equivalent
to
those
of
the
original
ELDR
while
reducing
the
training
time
by
up
to
97%
especially
when
using
a
large
hidden
layer
on
a
high
dimensionality
problem
</s>
<s>
Moreover
due
to
the
reusable
prediction
results
the
computation
time
of
the
fELDR-assisted
SAEA
can
be
further
decreased
by
79.5%
when
compared
with
that
of
the
original
ELDR-assisted
SAEA
</s>
<s>
The
reduced
training
time
and
reusable
prediction
results
of
fELDR
render
it
feasible
to
apply
ELDR
to
high-dimensional
optimization
problems
and
realize
a
high
prediction
accuracy
with
a
large
number
of
hidden
neurons
.
</s>