<s>
Smadasyn-boosted
cross-project
transfer
learning
for
effective
security
fault
prediction
</s>
<s>
Purpose
Security-related
software
fault
prediction
is
essential
yet
challenging
due
to
limited
labeled
vulnerability
data
and
the
inconsistency
of
fault
patterns
across
software
projects
</s>
<s>
This
study
aims
to
improve
the
generalizability
of
fault
prediction
models
using
a
cross-project
learning
approach
</s>
<s>
Method
We
propose
a
cross-project
transfer
learning
framework
for
security
fault
prediction
enhanced
by
feature
distribution
alignment
techniques
including
Kolmogorov
Smirnov
KS
test
Anderson
Darling
test
and
Pearson
correlation
</s>
<s>
To
effectively
address
the
issue
of
class
imbalance
prevalent
in
vulnerability
datasets
we
introduce
SMADASYN
a
hybrid
oversampling
method
that
integrates
the
strengths
of
SMOTE
Synthetic
Minority
Oversampling
Technique
and
ADASYN
Adaptive
Synthetic
Sampling
</s>
<s>
The
proposed
approach
is
empirically
validated
across
six
Apache
software
projects
using
a
range
of
classifiers
Decision
Tree
Naive
Bayes
Logistic
Regression
and
Random
Forest
along
with
ensemble
methods
such
as
Bagging
Boosting
and
Stacking
</s>
<s>
Results
Experimental
results
demonstrate
that
Random
Forest
consistently
achieves
the
highest
performance
particularly
in
terms
of
F1-score
and
recall
</s>
<s>
Statistical
validation
using
the
Friedman
test
and
Nemenyi
post-hoc
analysis
confirms
the
significance
and
robustness
of
the
results
across
datasets
</s>
<s>
Conclusion
The
proposed
method
effectively
enhances
security
fault
prediction
in
cross-project
scenarios
</s>
<s>
By
combining
feature
alignment
and
advanced
sampling
techniques
the
framework
delivers
accurate
and
generalizable
predictions
offering
practical
value
for
software
security
assurance
.
</s>