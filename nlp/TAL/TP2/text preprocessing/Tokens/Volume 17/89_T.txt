<s>
Intelligent
mobility
planning
for
a
cost-effective
object
follower
mobile
robotic
system
with
obstacle
avoidance
using
robot
vision
and
deep
learning
</s>
<s>
Few
industries
use
manually
controlled
robots
or
automobiles
to
carry
material
to
the
desired
position
and
in
some
cases
man
power
are
used
due
to
a
lack
of
money
</s>
<s>
This
cannot
be
used
all
the
time
in
all
places
and
all
conditions
</s>
<s>
So
it
is
very
tranquil
to
have
robots
which
can
follow
a
specific
human
by
following
the
unique
coloured
object
held
by
that
person
</s>
<s>
So
we
propose
a
robotic
system
that
uses
robot
vision
and
deep
learning
to
get
the
required
linear
and
angular
velocities
which
are
ν
and
ω
respectively
making
the
robot
avoid
static
and
dynamic
obstacles
when
following
the
unique
coloured
object
</s>
<s>
We
propose
a
novel
LSTM
cell
called
TF-LSTM
which
makes
the
proposed
methodology
very
accurate
in
tracking
the
object
in
3D
space
</s>
<s>
TF-LSTMs
or
target
follower
LSTMs
are
inspired
by
the
traditional
LSTMs
and
give
a
meagre
error
in
linear
and
angular
velocity
prediction
</s>
<s>
The
PI
controller
which
was
used
to
control
the
linear
and
angular
velocities
which
in
turn
controls
the
position
of
the
robot
gave
us
impressive
results
and
this
methodology
outperforms
all
other
methodologies
for
precise
target
tracking
in
performance
comparision
</s>
<s>
The
proposed
TF-LSTM
gave
us
an
accuracy
of
96.1%
average
linear
jerk
of
0.4
m/s3
average
angular
jerk
of
30
degrees/s3
average
clearance
of
0.514
m
maintaining
no
collosions
with
the
obstacles
.
</s>