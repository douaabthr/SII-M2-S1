<s>
A
comparative
analysis
of
deep
neural
network
architectures
for
sentence
classification
using
genetic
algorithm
</s>
<s>
Because
of
the
number
of
different
architectures
numerous
settings
of
their
hyper-parameters
and
disparity
among
their
sizes
it
is
difficult
to
equitably
compare
various
deep
neural
network
DNN
architectures
for
sentence
classification
</s>
<s>
Evolutionary
algorithms
are
emerging
as
a
popular
method
for
the
automatic
selection
of
architectures
and
hyperparameters
for
DNNs
whose
generalisation
performance
is
heavily
impacted
by
such
settings
</s>
<s>
Most
of
the
work
in
this
area
is
done
in
the
image
domain
leaving
text
analysis
another
prominent
application
domain
of
deep
learning
largely
absent
</s>
<s>
Besides
literature
presents
conflicting
claims
regarding
the
superiority
of
one
DNN
architecture
over
others
in
the
context
of
sentence
classification
</s>
<s>
To
address
this
issue
we
propose
a
genetic
algorithm
GA
for
optimising
the
architectural
and
hyperparameter
settings
in
different
DNN
types
for
sentence
classification
</s>
<s>
To
enable
the
representation
of
the
wide
variety
of
architectures
and
hyperparameters
utilised
in
DNNs
we
employed
a
generalised
and
flexible
encoding
scheme
in
our
GA
</s>
<s>
Our
study
involves
optimising
two
convolutional
and
three
recurrent
architectures
to
ensure
a
fair
and
unbiased
evaluation
of
their
performance
</s>
<s>
Furthermore
we
explore
the
effects
of
using
F1
score
versus
accuracy
as
a
performance
metric
during
evolutionary
optimisation
of
those
architectures
</s>
<s>
Our
results
using
ten
datasets
show
that
in
general
the
architectures
and
hyperparameters
evolved
using
the
F1
score
tended
to
outperform
those
evolved
using
accuracy
and
in
the
case
of
CNN
and
BiLSTM
the
results
were
significant
in
statistical
measures
</s>
<s>
Of
the
five
architectures
considered
the
GA-evolved
gated
recurrent
unit
GRU
performed
the
strongest
overall
achieving
good
generalisation
performance
while
using
relatively
few
trainable
parameters
establishing
GRU
as
the
preferred
architecture
for
the
sentence
classification
task
</s>
<s>
The
optimised
architectures
exhibited
comparable
performance
with
the
state-of-the-art
given
the
large
difference
in
trainable
parameters
.
</s>