<s>
A
multi-task
meta-learner-based
ensemble
for
robust
facial
expression
recognition
in-the-wild
</s>
<s>
Facial
expression
recognition
is
a
topic
of
significant
interest
in
affective
computing
</s>
<s>
However
prior
datasets
and
studies
have
primarily
focused
on
recognizing
facial
expressions
in
controlled
environments
limiting
their
generalizability
to
realistic
context
</s>
<s>
Thus
despite
recent
advancements
recognizing
facial
expressions
accurately
in
wild
scenarios
remains
a
challenging
task
</s>
<s>
In
this
work
we
propose
an
ensemble
model
based
on
multi-task
meta-learner
that
utilizes
a
pool
of
CNN
classifiers
while
dynamically
selecting
and
fusing
the
optimal
ensemble
in
order
to
recognize
facial
expressions
more
effectively
in
the
wild
</s>
<s>
The
suggested
scheme
leverages
the
output
probabilities
of
base
learners
as
meta-features
and
integrates
multi-label
classification
into
dynamic
ensemble
selection
</s>
<s>
As
best
as
we
know
this
is
the
first
investigation
of
multi-task
learning
at
the
meta-learning
level
in
the
context
of
facial
expression
recognition
</s>
<s>
In
particular
we
introduce
an
effective
meta-learner
that
combines
the
strengths
of
stacking
and
dynamic
ensemble
selection
</s>
<s>
The
proposed
approach
has
been
evaluated
exhaustively
on
several
challenging
datasets
including
RAF-DB
FER2013
and
FERPlus
and
the
obtained
results
demonstrate
that
the
ensemble
CNN
outperforms
individual
CNN
models
consistently
while
achieving
high
performance
across
all
datasets
</s>
<s>
We
further
demonstrate
the
generalizability
of
the
proposed
approach
by
performing
cross-dataset
evaluation
.
</s>