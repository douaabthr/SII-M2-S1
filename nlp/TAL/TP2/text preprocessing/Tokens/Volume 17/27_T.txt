<s>
Centralized
reinforcement
learning
for
multi-agent
cooperative
environments
</s>
<s>
We
study
reinforcement
learning
methods
in
multi-agent
domains
where
a
central
controller
collects
all
information
and
decides
an
action
for
every
agent
</s>
<s>
However
multi-agent
reinforcement
learning
MARL
suffers
from
the
combinatorial
explosion
of
action
space
</s>
<s>
In
this
work
we
propose
an
improved
proximal
policy
optimization
PPO
algorithm
whose
neural
network
is
based
on
attention
mechanism
to
solve
the
combinatorial
explosion
issue
</s>
<s>
Our
model
outputs
joint-action
instead
of
distributed
action
</s>
<s>
Parameter
sharing
of
attention
mechanism
enables
the
size
of
neural
network
linearly
with
local
observation
s
length
of
single
agent
regardless
of
the
agents
number
</s>
<s>
Besides
credit
assignment
of
multi-agent
is
naturally
addressed
by
gradient
ascent
in
the
attention
layer
</s>
<s>
Experiment
results
demonstrate
that
our
method
outperforms
independent
PPO
and
centralized
PPO
with
other
networks
.
</s>