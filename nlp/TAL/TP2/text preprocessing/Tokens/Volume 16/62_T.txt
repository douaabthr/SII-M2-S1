<s>
Initializing
hyper-parameter
tuning
with
a
metaheuristic-ensemble
method
a
case
study
using
time-series
weather
data
</s>
<s>
Hyper-parameter
optimization
HO
regardless
of
the
type
of
optimization
inherently
not
only
increases
the
completion
time
of
the
algorithm
to
be
optimized
but
also
creates
a
remarkable
computational
burden
</s>
<s>
However
employing
the
most
suitable
HO
technique
for
a
specific
problem
may
not
be
sufficient
to
improve
the
performance
of
the
selected
machine
learning
algorithm
</s>
<s>
In
such
cases
it
is
common
to
deploy
default
values
of
the
initialization
hyper-parameters
of
HO
</s>
<s>
Instead
a
configured
set
of
initialization
hyper-parameters
of
HO
is
significantly
more
impactful
than
a
default
mode
of
HO
</s>
<s>
In
this
study
a
metaheuristic
ensemble
technique
is
proposed
to
configure
the
initialization
hyper-parameters
of
HO
</s>
<s>
The
proposed
method
is
devised
after
an
extensive
time
analysis
of
metaheuristics
and
applied
to
Echo
State
Network
ESN
</s>
<s>
The
experiment
performed
with
weather
forecast
data
shows
that
metaheuristic
initialization
methods
are
quite
compatible
with
evolutionary
algorithms
</s>
<s>
In
the
benchmark
the
proposed
method
outperformed
two
alternatives
</s>
<s>
Probabilistic
methods
such
as
Bayesian
optimization
are
not
preferable
for
metaheuristic
initialization
methods
according
to
the
results
of
the
experiment
</s>
<s>
Metaheuristic
hyper-parameter
initialization
methods
can
be
performed
by
utilizing
Random
search
that
provides
a
moderate
performance
in
which
there
are
hardware-restricted
sources
</s>
<s>
Last
the
hyper-parameter
calledleakingrateof
ESN
is
the
most
sensitive
one
and
creates
the
largest
churns
in
the
prediction
performance
.
</s>