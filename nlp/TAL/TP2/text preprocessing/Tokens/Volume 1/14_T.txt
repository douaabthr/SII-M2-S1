<s>
MENNAG
a
modular
regular
and
hierarchical
encoding
for
neural-networks
based
on
attribute
grammars
</s>
<s>
Recent
work
in
the
evolutionary
computation
field
suggests
that
the
implementation
of
the
principles
of
modularity
functional
localization
of
functions
repetition
multiple
use
of
the
same
sub-structure
and
hierarchy
recursive
composition
of
sub-structures
could
improve
the
evolvability
of
complex
systems
</s>
<s>
The
generation
of
neural
networks
through
evolutionary
algorithms
should
in
particular
benefit
from
an
adapted
use
of
these
notions
</s>
<s>
We
have
consequently
developed
modular
encoding
for
neural
networks
based
on
attribute
grammars
MENNAG
a
new
encoding
designed
to
generate
the
structure
of
neural
networks
and
parameters
with
evolutionary
algorithms
while
explicitly
enabling
these
three
above-mentioned
principles
</s>
<s>
We
expressed
this
encoding
in
the
formalism
of
attribute
grammars
in
order
to
facilitate
understanding
and
future
modifications
</s>
<s>
It
has
been
tested
on
two
preliminary
benchmark
problems
cart-pole
control
and
robotic
arm
control
the
latter
being
specifically
designed
to
evaluate
the
repetition
capabilities
of
an
encoding
</s>
<s>
We
compared
MENNAG
to
a
direct
encoding
ModNet
NEAT
a
multi-layer
perceptron
with
a
fixed
structure
and
to
reference
controllers
</s>
<s>
Results
show
that
MENNAG
performs
better
than
comparable
encodings
on
both
problems
suggesting
a
promising
potential
for
future
applications
.
</s>