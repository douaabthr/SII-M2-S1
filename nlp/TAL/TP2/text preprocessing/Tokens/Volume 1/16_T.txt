<s>
Evolution
of
internal
dynamics
for
neural
network
nodes
</s>
<s>
Most
artificial
neural
networks
have
nodes
that
apply
a
simple
static
transfer
function
such
as
a
sigmoid
or
gaussian
to
their
accumulated
inputs
</s>
<s>
This
contrasts
with
biological
neurons
whose
transfer
functions
are
dynamic
and
driven
by
a
rich
internal
structure
</s>
<s>
Our
artificial
neural
network
approach
which
we
callstate-enhanced
neural
networks
uses
nodes
with
dynamic
transfer
functions
based
onn-dimensional
real-valued
internal
state
</s>
<s>
This
internal
state
provides
the
nodes
with
memory
of
past
inputs
and
computations
</s>
<s>
The
state
update
rules
which
determine
the
internal
dynamics
of
a
node
are
optimized
by
an
evolutionary
algorithm
to
fit
a
particular
task
and
environment
</s>
<s>
We
demonstrate
the
effectiveness
of
the
approach
in
comparison
to
certain
types
of
recurrent
neural
networks
using
a
suite
of
partially
observable
Markov
decision
processes
as
test
problems
</s>
<s>
These
problems
involve
both
sequence
detection
and
simulated
mice
in
mazes
and
include
four
advanced
benchmarks
proposed
by
other
researchers
.
</s>