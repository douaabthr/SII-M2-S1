<s>
qualit
differ
between
evolutionari
strategi
and
reinforc
learn
method
for
control
of
autonom
agent
</s>
<s>
in
this
paper
we
analyz
the
qualit
differ
between
evolutionari
strategi
and
reinforc
learn
algorithm
by
focus
on
two
popular
state-of-the-art
algorithm
the
openai-
evolutionari
strategi
and
the
proxim
polici
optim
ppo
reinforc
learn
algorithm
the
most
similar
method
of
the
two
famili
</s>
<s>
we
analyz
how
the
method
differ
with
respect
to
i
general
efficaci
ii
abil
to
cope
with
reward
which
are
spars
in
time
iii
propensity/capac
to
discov
minim
solut
iv
depend
on
reward
shape
and
v
abil
to
cope
with
variat
of
the
environment
condit
</s>
<s>
the
analysi
of
the
perform
and
of
the
behavior
strategi
display
by
the
agent
train
with
the
two
method
on
benchmark
problem
enabl
us
to
demonstr
qualit
differ
which
were
not
identifi
in
previous
studi
to
identifi
the
relat
weak
of
the
two
method
and
to
propos
way
to
amelior
some
of
those
weak
</s>
<s>
we
show
that
the
characterist
of
the
reward
function
has
a
strong
impact
which
vari
qualit
not
onli
for
the
openai-
evolutionari
algorithm
and
the
ppo
reinforc
learn
algorithm
but
also
for
other
reinforc
learn
algorithm
thus
demonstr
the
import
of
optim
the
characterist
of
the
reward
function
to
the
algorithm
use
.
</s>