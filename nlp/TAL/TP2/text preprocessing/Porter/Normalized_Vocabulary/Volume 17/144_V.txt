.
1st
2nd
</s>
<s>
a
accord
accuraci
adabelief
adam
adapt
addit
adjust
also
an
and
angular
angulargrad
appli
approach
area
attain
base
been
best
better
both
but
by
calcul
can
chang
cifar10
cifar100
classif
cnn
co
code
com/utpalnandi/sqfm-a-novel-adaptive-optimization-scheme-for-deep-learning-model
compar
comparison
consist
contrast
converg
dataset
deep
deliv
demonstr
densenet121
depend
develop
diffgrad
doe
due
dure
effect
empir
factor
first
for
function
github
give
global
good
gradient
gradual
ha
http
imag
imagenet
import
in
is
it
learn
less
limit
link
long
loss
maxim
method
minim
minima
minimum
mnist
model
moment
momentum
most
necessit
network
non-convex
non-neg
not
novel
of
on
one
optim
order
overcom
overshoot
paramet
perform
phase
present
propos
radam
requir
research
resnet16
resnet18
resnet50
result
rosenbrock
scheme
sgd
sgdm
size
smoother
sourc
sqfm
squar
step
studi
suggest
take
tan
techniqu
than
that
the
these
those
time
to
train
trajectori
updat
use
valu
vgg34
when
which
with
yogi
zigzag