.
1st
2nd
</s>
<s>
a
acc
accord
adabeliev
adam
adapt
addit
adjust
also
an
and
angul
angulargrad
apply
approach
area
attain
bas
been
best
bet
both
but
by
calc
can
chang
cifar10
cifar100
class
cnn
cod
com/utpalnandi/sqfm-a-novel-adaptive-optimization-scheme-for-deep-learning-model
comp
comparison
consist
contrast
converg
cos
dataset
deep
del
demonst
densenet121
depend
develop
diffgrad
doe
due
dur
effect
empir
fact
first
for
funct
github
giv
glob
good
grad
grady
has
https
im
imagenet
import
in
is
it
learn
less
limit
link
long
loss
maxim
method
minim
mnist
model
mom
moment
most
necessit
network
non-convex
non-negative
not
novel
of
on
optim
ord
overcom
overshoot
paramet
perform
phas
pres
propos
radam
requir
research
resnet16
resnet18
resnet50
result
rosenbrock
scheme
sgd
sgdm
siz
smooth
sourc
sqfm
squ
step
study
suggest
tak
tan
techn
than
that
the
thes
thos
tim
to
train
traject
upd
us
valu
vgg34
when
which
with
yog
zigz