mutual inform for featur select estim or count
in classif featur select is an import pre-process step to simplifi the dataset and improv the data represent qualiti which make classifi becom better easier to train and understand
becaus of an abil to analys non-linear interact between featur mutual inform has been wide appli to featur select
along with count approach a tradit way to calcul mutual inform mani mutual inform estim have been propos to allow mutual inform to work direct on continu dataset
this work focus on compar the effect of count approach and kernel densiti estim kde approach in featur select use particl swarm optimis as a search mechan
the experiment result on 15 differ dataset show that kde can work well on both continu and discret dataset
in addit featur subset evolv by kde achiev similar or better classif perform than the count approach
furthermor the result on artifici dataset with various interact show that kde is abl to captur correct the interact between featur in both relev and redund which can not be achiev by use the count approach .