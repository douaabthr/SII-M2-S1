Evolving scalable and modular adaptive networks with Developmental Symbolic Encoding
Evolutionary neural networks or neuroevolution appear to be a promising way to build versatile adaptive systems combining evolution and learning
One of the most challenging problems of neuroevolution is finding a scalable and robust genetic representation which would allow to effectively grow increasingly complex networks for increasingly complex tasks
In this paper we propose a novel developmental encoding for networks featuring scalability modularity regularity and hierarchy
The encoding allows to represent structural regularities of networks and build them from encapsulated and possibly reused subnetworks
These capabilities are demonstrated on several test problems
In particular for parity and symmetry problems we evolve solutions which are fully general with respect to the number of inputs
We also evolve scalable and modular weightless recurrent networks capable of autonomous learning in a simple generic classification task
The encoding is very flexible and we demonstrate this by evolving networks capable of learning via neuromodulation
Finally we evolve modular solutions to the retina problem for which another well known neuroevolution method HyperNEAT was previously shown to fail
The proposed encoding outperformed HyperNEAT and Cellular Encoding also in another experiment in which certain connectivity patterns must be discovered between layers
Therefore we conclude the proposed encoding is an interesting and competitive approach to evolve networks .