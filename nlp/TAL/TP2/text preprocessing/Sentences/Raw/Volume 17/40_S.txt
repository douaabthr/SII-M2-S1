Special issue on Towards robust explainable and interpretable artificial intelligence
The complexity of modern artificial intelligence AI models has raised the question about their interpretability
The terms interpretability and explainability have been used interchangeably by researchers
These two terms sound very closely related although they have to be meant differently
Interpretability is mostly related to the outcome of the cause-and-effect relationship given the inputs of a system
Explainability deals with the internal logic of a machine learning system
It aims to characterize model accuracy and transparency in AI-powered decision making
It is clear that there is a need for a proper mathematical formalism that is still missing
Hence there is a trade-off between the performance of a machine learning model and its ability to produce explainable and interpretable predictions
The study of robust systems which are also explainable and interpretable is still under way .