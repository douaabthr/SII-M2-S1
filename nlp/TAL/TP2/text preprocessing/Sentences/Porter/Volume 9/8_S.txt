mutual inform for featur select estim or count
in classif featur select is an import pre-process step to simplifi the dataset and improv the data represent qualiti which make classifi becom better easier to train and understand
becaus of an abil to analys non-linear interact between featur mutual inform ha been wide appli to featur select
along with count approach a tradit way to calcul mutual inform mani mutual inform estim have been propos to allow mutual inform to work directli on continu dataset
thi work focus on compar the effect of count approach and kernel densiti estim kde approach in featur select use particl swarm optimis as a search mechan
the experiment result on 15 differ dataset show that kde can work well on both continu and discret dataset
in addit featur subset evolv by kde achiev similar or better classif perform than the count approach
furthermor the result on artifici dataset with variou interact show that kde is abl to captur correctli the interact between featur in both relev and redund which can not be achiev by use the count approach .